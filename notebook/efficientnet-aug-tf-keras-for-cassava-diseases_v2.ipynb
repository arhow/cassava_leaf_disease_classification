{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "literary-treat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\anaconda3\\envs\\tf_gpu23-2\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb3 (Functional)  (None, 16, 16, 1536)      10783535  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 7685      \n",
      "=================================================================\n",
      "Total params: 10,791,220\n",
      "Trainable params: 10,703,917\n",
      "Non-trainable params: 87,303\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import random\n",
    "import cv2\n",
    "from imgaug import augmenters as iaa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.experimental import CosineDecay\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomCrop,CenterCrop, RandomRotation\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug = True\n",
    "    training_percentage = .8\n",
    "    epochs = 8\n",
    "    batch_size = 4\n",
    "    image_size = 512\n",
    "    dropout_rate = 0.4\n",
    "\n",
    "class PATH:\n",
    "    train_folder = '../input/cassava-leaf-disease-classification/train_images/'\n",
    "    train_csv = \"../input/cassava-leaf-disease-classification/train.csv\"\n",
    "    ef_weight = '../model/efficientnetb3_notop.h5'\n",
    "    ef_noisy_student_weight = '../model/efficientnetb3_notop.h5'\n",
    "\n",
    "if CFG.debug:\n",
    "    CFG.epochs = 1\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# PREPARE DATA\n",
    "# ====================================================\n",
    "samples_df = pd.read_csv(PATH.train_csv)\n",
    "samples_df = shuffle(samples_df, random_state=42)\n",
    "samples_df[\"filepath\"] = PATH.train_folder+samples_df[\"image_id\"]\n",
    "training_item_count = int(len(samples_df)*CFG.training_percentage)\n",
    "validation_item_count = len(samples_df)-int(len(samples_df)*CFG.training_percentage)\n",
    "training_df = samples_df[:training_item_count]\n",
    "validation_df = samples_df[training_item_count:]\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# BUILD GRAPH\n",
    "# ====================================================\n",
    "\n",
    "def load_image_and_label_from_path(image_path, label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img, label\n",
    "\n",
    "def adapt_mode(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = layers.experimental.preprocessing.Rescaling(1.0 / 255)(img)\n",
    "    return img\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "training_data = tf.data.Dataset.from_tensor_slices((training_df.filepath.values, training_df.label.values))\n",
    "validation_data = tf.data.Dataset.from_tensor_slices((validation_df.filepath.values, validation_df.label.values))\n",
    "training_data = training_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\n",
    "validation_data = validation_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\n",
    "training_data_batches = training_data.shuffle(buffer_size=1000).batch(CFG.batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "validation_data_batches = validation_data.shuffle(buffer_size=1000).batch(CFG.batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "adapt_data = tf.data.Dataset.from_tensor_slices(training_df.filepath.values)\n",
    "adapt_data = adapt_data.map(adapt_mode, num_parallel_calls=AUTOTUNE)\n",
    "adapt_data_batches = adapt_data.shuffle(buffer_size=1000).batch(CFG.batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_graph(init_weights=PATH.ef_weight)\n",
    "\n",
    "    # build graph\n",
    "    data_augmentation_layers = tf.keras.Sequential(\n",
    "        [\n",
    "            layers.experimental.preprocessing.RandomCrop(height=CFG.image_size, width=CFG.image_size),\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(0.25),\n",
    "            layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n",
    "            layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n",
    "        ]\n",
    "    )\n",
    "    n_ouput = len(sorted(training_df.label.unique()))\n",
    "\n",
    "    input_shape = (CFG.image_size, CFG.image_size, 3)\n",
    "    \n",
    "    efficientnet = EfficientNetB3(\n",
    "        weights=init_weights,\n",
    "        include_top=False,\n",
    "        input_shape=input_shape,\n",
    "        drop_connect_rate=CFG.dropout_rate)\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    augmented = data_augmentation_layers(inputs)\n",
    "    efficientnet = efficientnet(augmented)\n",
    "    pooling = layers.GlobalAveragePooling2D()(efficientnet)\n",
    "    dropout = layers.Dropout(CFG.dropout_rate)(pooling)\n",
    "    outputs = Dense(n_ouput, activation=\"softmax\")(dropout)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # set train param\n",
    "    model.get_layer('efficientnetb3').get_layer('normalization').adapt(adapt_data_batches)\n",
    "    decay_steps = int(round(len(training_df)/CFG.batch_size))*CFG.epochs\n",
    "    cosine_decay = CosineDecay(initial_learning_rate=1e-4, decay_steps=decay_steps, alpha=0.3)\n",
    "    callbacks = [ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(cosine_decay), metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_graph()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "constant-martin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(training_df.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amended-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# TRAIN\n",
    "# ===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LESSION = 1\n",
    "\n",
    "# run model \n",
    "history = model.fit(training_data_batches, epochs = CFG.epochs, validation_data=validation_data_batches, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-counter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "industrial-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/4280 [..............................] - ETA: 8:36 - loss: 1.5341 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0618s vs `on_train_batch_end` time: 0.1775s). Check your callbacks.\n",
      "4280/4280 [==============================] - 1095s 256ms/step - loss: 0.6297 - accuracy: 0.7859 - val_loss: 0.4449 - val_accuracy: 0.8430\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_data_batches, epochs = CFG.epochs, validation_data=validation_data_batches, callbacks=callbacks)\n",
    "# pd.DataFrame(history.his).to_csv('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "perceived-index",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6297047734260559],\n",
       " 'accuracy': [0.7858853936195374],\n",
       " 'val_loss': [0.44493407011032104],\n",
       " 'val_accuracy': [0.8429906368255615]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "velvet-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_augmentation_layers = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n",
    "        layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n",
    "    ]\n",
    ")\n",
    "\n",
    "def scan_over_image(img_path, crop_size=512):\n",
    "    '''\n",
    "    Will extract 512x512 images covering the whole original image\n",
    "    with some overlap between images\n",
    "    '''\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    img_height, img_width = img.size\n",
    "    img = np.array(img)\n",
    "    \n",
    "    y = random.randint(0,img_height-crop_size)\n",
    "    x = random.randint(0,img_width-crop_size)\n",
    "\n",
    "    x_img_origins = [0,img_width-crop_size]\n",
    "    y_img_origins = [0,img_height-crop_size]\n",
    "    img_list = []\n",
    "    for x in x_img_origins:\n",
    "        for y in y_img_origins:\n",
    "            img_list.append(img[x:x+crop_size , y:y+crop_size,:])\n",
    "  \n",
    "    return np.array(img_list)\n",
    "\n",
    "\n",
    "def predict_and_vote(image_filename, folder, TTA_runs=4):\n",
    "    '''\n",
    "    Run the model over 4 local areas of the given image,\n",
    "    before making a decision depending on the most predicted\n",
    "    disease.\n",
    "    '''\n",
    "    \n",
    "    #apply TTA to each of the 4 images and sum all predictions for each local image\n",
    "    localised_predictions = []\n",
    "    local_image_list = scan_over_image(folder+image_filename)\n",
    "    for local_image in local_image_list:\n",
    "        duplicated_local_image = tf.convert_to_tensor(np.array([local_image for i in range(TTA_runs)]))\n",
    "        augmented_images = test_time_augmentation_layers(duplicated_local_image)\n",
    "        \n",
    "        predictions = model.predict(augmented_images)\n",
    "        localised_predictions.append(np.sum(predictions, axis=0))\n",
    "    \n",
    "    #sum all predictions from all 4 images and retrieve the index of the highest value\n",
    "    global_predictions = np.sum(np.array(localised_predictions),axis=0)\n",
    "    final_prediction = np.argmax(global_predictions)\n",
    "    \n",
    "    return final_prediction\n",
    "\n",
    "def run_predictions_over_image_list(image_list, folder):\n",
    "    predictions = []\n",
    "    with tqdm(total=len(image_list)) as pbar:\n",
    "        for image_filename in image_list:\n",
    "            pbar.update(1)\n",
    "            predictions.append(predict_and_vote(image_filename, folder))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "brown-operator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10234</th>\n",
       "      <td>2824543301.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4763</th>\n",
       "      <td>184909120.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>2602456265.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>1331491784.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17431</th>\n",
       "      <td>414363375.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label  \\\n",
       "10234  2824543301.jpg      3   \n",
       "4763    184909120.jpg      3   \n",
       "9062   2602456265.jpg      3   \n",
       "1874   1331491784.jpg      3   \n",
       "17431   414363375.jpg      3   \n",
       "\n",
       "                                                filepath  \n",
       "10234  ../input/cassava-leaf-disease-classification/t...  \n",
       "4763   ../input/cassava-leaf-disease-classification/t...  \n",
       "9062   ../input/cassava-leaf-disease-classification/t...  \n",
       "1874   ../input/cassava-leaf-disease-classification/t...  \n",
       "17431  ../input/cassava-leaf-disease-classification/t...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "electoral-table",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4280/4280 [18:01<00:00,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_df[\"results\"] = run_predictions_over_image_list(validation_df[\"image_id\"], PATH.train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "filled-bread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10234</th>\n",
       "      <td>2824543301.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4763</th>\n",
       "      <td>184909120.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>2602456265.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>1331491784.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17431</th>\n",
       "      <td>414363375.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label  \\\n",
       "10234  2824543301.jpg      3   \n",
       "4763    184909120.jpg      3   \n",
       "9062   2602456265.jpg      3   \n",
       "1874   1331491784.jpg      3   \n",
       "17431   414363375.jpg      3   \n",
       "\n",
       "                                                filepath  results  \n",
       "10234  ../input/cassava-leaf-disease-classification/t...        3  \n",
       "4763   ../input/cassava-leaf-disease-classification/t...        3  \n",
       "9062   ../input/cassava-leaf-disease-classification/t...        3  \n",
       "1874   ../input/cassava-leaf-disease-classification/t...        3  \n",
       "17431  ../input/cassava-leaf-disease-classification/t...        3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "southern-audit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858411214953271"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(validation_df['label']==validation_df['results'])/validation_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-spanking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
