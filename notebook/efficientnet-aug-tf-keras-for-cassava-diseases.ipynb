{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035649,
     "end_time": "2021-01-06T02:14:51.431827",
     "exception": false,
     "start_time": "2021-01-06T02:14:51.396178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EfficientNet+Augmentation for Cassava Disease Classification using TF.Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034359,
     "end_time": "2021-01-06T02:14:51.501261",
     "exception": false,
     "start_time": "2021-01-06T02:14:51.466902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook presents a full pipeline to load the data, apply advanced data augmentation, train an EfficientNet and use the model to predict over the test images. To make it possible to run within the allocated time for notebooks, this notebook will only present a single fold with a split of 80% for training and 20% for validation. Due to the original image size of 600x800 pixels, we will randomly crop 512x512 images from original images in order to keep the highest image resolution possible for our model training. Previous versions of this notebook used resized images and the results were extremely poor in comparison (~0.42 accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033756,
     "end_time": "2021-01-06T02:14:51.567895",
     "exception": false,
     "start_time": "2021-01-06T02:14:51.534139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below are some version notes which were written at version 20 so I only included what I could remember."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032281,
     "end_time": "2021-01-06T02:14:51.634386",
     "exception": false,
     "start_time": "2021-01-06T02:14:51.602105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Version notes:\n",
    "* 27: Fix bug in the TTA process.\n",
    "* 26: Move from using `ImageDataGenerator` to `tf.data` to load data into the model. This allows to tune the Normalization layer in the pretrained EfficientNetB3 model provided by `tf.keras`. By default, images are normalized using the `imagenet` dataset's mean and standard deviation. *- score: 0.888*\n",
    "* 24: Test CosineDecay instead of ReduceLRonPlateau and increase the dropout rate within the EfficientNetB3 model. *- score: 0.885*\n",
    "* 22: Replace the custom generator and data augmentation using `imgaug` with the new Keras preprocessing layers. Also increase the image size from 300x300 to 512x512. *- score: 0.880*\n",
    "* 21: *- score: 0.883*\n",
    "* 20: Fix bug activating the \"training mode\" by default in the custom generator, even during validation. Removed data standardization and class weights, simplify the bottleneck layers of the model, and remove the dropout from the data augmentation techniques. *- score: 0.873*\n",
    "* 17: Additional data augmentation techniques. *- score: 0.821*\n",
    "* 16: Tighter scan of the images at test time. *- score: 0.857*\n",
    "* 15: Add data standardization. (Cannot remember if there was a bug but the score was abnormaly low) *- score: 0.692*\n",
    "* 11: Train the model by randomly cropping 300x300pixel tiles from the original images *- score: 0.847*\n",
    "* 9: Classification from resized images. *- score: 0.421* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 7.646706,
     "end_time": "2021-01-06T02:14:59.313553",
     "exception": false,
     "start_time": "2021-01-06T02:14:51.666847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\anaconda3\\envs\\tf_gpu23-2\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import random\n",
    "import cv2\n",
    "from imgaug import augmenters as iaa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.experimental import CosineDecay\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomCrop,CenterCrop, RandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.040553,
     "end_time": "2021-01-06T02:14:59.457397",
     "exception": false,
     "start_time": "2021-01-06T02:14:59.416844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_folder = '../input/cassava-leaf-disease-classification/train_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.10876,
     "end_time": "2021-01-06T02:14:59.599813",
     "exception": false,
     "start_time": "2021-01-06T02:14:59.491053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_df = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n",
    "samples_df = shuffle(samples_df, random_state=42)\n",
    "samples_df[\"filepath\"] = training_folder+samples_df[\"image_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.041416,
     "end_time": "2021-01-06T02:14:59.742251",
     "exception": false,
     "start_time": "2021-01-06T02:14:59.700835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_percentage = 0.8\n",
    "training_item_count = int(len(samples_df)*training_percentage)\n",
    "validation_item_count = len(samples_df)-int(len(samples_df)*training_percentage)\n",
    "training_df = samples_df[:training_item_count]\n",
    "validation_df = samples_df[training_item_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.042327,
     "end_time": "2021-01-06T02:14:59.886390",
     "exception": false,
     "start_time": "2021-01-06T02:14:59.844063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "image_size = 512\n",
    "input_shape = (image_size, image_size, 3)\n",
    "dropout_rate = 0.4\n",
    "classes_to_predict = sorted(training_df.label.unique())\n",
    "n_ouput = len(classes_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 2.584349,
     "end_time": "2021-01-06T02:15:02.577371",
     "exception": false,
     "start_time": "2021-01-06T02:14:59.993022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = tf.data.Dataset.from_tensor_slices((training_df.filepath.values, training_df.label.values))\n",
    "validation_data = tf.data.Dataset.from_tensor_slices((validation_df.filepath.values, validation_df.label.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.145447,
     "end_time": "2021-01-06T02:15:02.757485",
     "exception": false,
     "start_time": "2021-01-06T02:15:02.612038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image_and_label_from_path(image_path, label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "training_data = training_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\n",
    "validation_data = validation_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.050934,
     "end_time": "2021-01-06T02:15:02.844084",
     "exception": false,
     "start_time": "2021-01-06T02:15:02.793150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data_batches = training_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "validation_data_batches = validation_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.131024,
     "end_time": "2021-01-06T02:15:03.080732",
     "exception": false,
     "start_time": "2021-01-06T02:15:02.949708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "adapt_data = tf.data.Dataset.from_tensor_slices(training_df.filepath.values)\n",
    "def adapt_mode(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = layers.experimental.preprocessing.Rescaling(1.0 / 255)(img)\n",
    "    return img\n",
    "\n",
    "adapt_data = adapt_data.map(adapt_mode, num_parallel_calls=AUTOTUNE)\n",
    "adapt_data_batches = adapt_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.363049,
     "end_time": "2021-01-06T02:15:03.556021",
     "exception": false,
     "start_time": "2021-01-06T02:15:03.192972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_augmentation_layers = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomCrop(height=image_size, width=image_size),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.25),\n",
    "        layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n",
    "        layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 8.081719,
     "end_time": "2021-01-06T02:15:14.090583",
     "exception": false,
     "start_time": "2021-01-06T02:15:06.008864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb3 (Functional)  (None, 16, 16, 1536)      10783535  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 7685      \n",
      "=================================================================\n",
      "Total params: 10,791,220\n",
      "Trainable params: 10,703,917\n",
      "Non-trainable params: 87,303\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "efficientnet = EfficientNetB3(#weights='../model/efficientnet-b3_noisy-student.h5', \n",
    "                              include_top=False, \n",
    "                              input_shape=input_shape, \n",
    "                              drop_connect_rate=dropout_rate)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "augmented = data_augmentation_layers(inputs)\n",
    "efficientnet = efficientnet(augmented)\n",
    "pooling = layers.GlobalAveragePooling2D()(efficientnet)\n",
    "dropout = layers.Dropout(dropout_rate)(pooling)\n",
    "outputs = Dense(n_ouput, activation=\"softmax\")(dropout)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 823.755777,
     "end_time": "2021-01-06T02:28:58.011550",
     "exception": false,
     "start_time": "2021-01-06T02:15:14.255773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.get_layer('efficientnetb3').get_layer('normalization').adapt(adapt_data_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.091558,
     "end_time": "2021-01-06T02:28:58.265203",
     "exception": false,
     "start_time": "2021-01-06T02:28:58.173645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "decay_steps = int(round(len(training_df)/batch_size))*epochs\n",
    "cosine_decay = CosineDecay(initial_learning_rate=1e-4, decay_steps=decay_steps, alpha=0.3)\n",
    "\n",
    "callbacks = [ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(cosine_decay), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 10089.702939,
     "end_time": "2021-01-06T05:17:08.023047",
     "exception": false,
     "start_time": "2021-01-06T02:28:58.320108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "   2/4280 [..............................] - ETA: 8:08 - loss: 1.5193 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0608s vs `on_train_batch_end` time: 0.1666s). Check your callbacks.\n",
      "4280/4280 [==============================] - 1015s 237ms/step - loss: 0.6378 - accuracy: 0.7794 - val_loss: 0.4713 - val_accuracy: 0.8285\n",
      "Epoch 2/8\n",
      "4280/4280 [==============================] - 1004s 235ms/step - loss: 0.4902 - accuracy: 0.8359 - val_loss: 0.4818 - val_accuracy: 0.8311\n",
      "Epoch 3/8\n",
      "4280/4280 [==============================] - 1018s 238ms/step - loss: 0.4390 - accuracy: 0.8505 - val_loss: 0.4388 - val_accuracy: 0.8474\n",
      "Epoch 4/8\n",
      "4280/4280 [==============================] - 1013s 237ms/step - loss: 0.3962 - accuracy: 0.8683 - val_loss: 0.4027 - val_accuracy: 0.8689\n",
      "Epoch 5/8\n",
      "4280/4280 [==============================] - 1009s 236ms/step - loss: 0.3763 - accuracy: 0.8753 - val_loss: 0.4537 - val_accuracy: 0.8456\n",
      "Epoch 6/8\n",
      "4280/4280 [==============================] - 1018s 238ms/step - loss: 0.3527 - accuracy: 0.8819 - val_loss: 0.3989 - val_accuracy: 0.8661\n",
      "Epoch 7/8\n",
      "4280/4280 [==============================] - 1011s 236ms/step - loss: 0.3319 - accuracy: 0.8884 - val_loss: 0.3712 - val_accuracy: 0.8713\n",
      "Epoch 8/8\n",
      "4280/4280 [==============================] - 1004s 235ms/step - loss: 0.3160 - accuracy: 0.8950 - val_loss: 0.3787 - val_accuracy: 0.8762\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_data_batches,\n",
    "                  epochs = epochs, \n",
    "                  validation_data=validation_data_batches,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 6.681043,
     "end_time": "2021-01-06T05:17:46.518718",
     "exception": false,
     "start_time": "2021-01-06T05:17:39.837675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss over epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6.367287,
     "end_time": "2021-01-06T05:18:25.806967",
     "exception": false,
     "start_time": "2021-01-06T05:18:19.439680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 6.774458,
     "end_time": "2021-01-06T05:18:13.060054",
     "exception": false,
     "start_time": "2021-01-06T05:18:06.285596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-963a37c31063>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": 6.460839,
     "end_time": "2021-01-06T05:18:39.124508",
     "exception": false,
     "start_time": "2021-01-06T05:18:32.663669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scan_over_image(img_path, crop_size=512):\n",
    "    '''\n",
    "    Will extract 512x512 images covering the whole original image\n",
    "    with some overlap between images\n",
    "    '''\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    img_height, img_width = img.size\n",
    "    img = np.array(img)\n",
    "    \n",
    "    y = random.randint(0,img_height-crop_size)\n",
    "    x = random.randint(0,img_width-crop_size)\n",
    "\n",
    "    x_img_origins = [0,img_width-crop_size]\n",
    "    y_img_origins = [0,img_height-crop_size]\n",
    "    img_list = []\n",
    "    for x in x_img_origins:\n",
    "        for y in y_img_origins:\n",
    "            img_list.append(img[x:x+crop_size , y:y+crop_size,:])\n",
    "  \n",
    "    return np.array(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "papermill": {
     "duration": 7.046026,
     "end_time": "2021-01-06T05:18:52.293972",
     "exception": false,
     "start_time": "2021-01-06T05:18:45.247946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def display_samples(img_path):\n",
    "#     '''\n",
    "#     Display all 512x512 images extracted from original images\n",
    "#     '''\n",
    "    \n",
    "#     img_list = scan_over_image(img_path)\n",
    "#     sample_number = len(img_list)\n",
    "#     fig = plt.figure(figsize = (8,sample_number))\n",
    "#     for i in range(0,sample_number):\n",
    "#         ax = fig.add_subplot(2, 4, i+1)\n",
    "#         ax.imshow(img_list[i])\n",
    "#         ax.set_title(str(i))\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# display_samples(\"../input/cassava-leaf-disease-classification/train_images/3412658650.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "papermill": {
     "duration": 6.224872,
     "end_time": "2021-01-06T05:19:19.570722",
     "exception": false,
     "start_time": "2021-01-06T05:19:13.345850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_time_augmentation_layers = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n",
    "        layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "papermill": {
     "duration": 6.090925,
     "end_time": "2021-01-06T05:19:31.976501",
     "exception": false,
     "start_time": "2021-01-06T05:19:25.885576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_and_vote(image_filename, folder, TTA_runs=4):\n",
    "    '''\n",
    "    Run the model over 4 local areas of the given image,\n",
    "    before making a decision depending on the most predicted\n",
    "    disease.\n",
    "    '''\n",
    "    \n",
    "    #apply TTA to each of the 4 images and sum all predictions for each local image\n",
    "    localised_predictions = []\n",
    "    local_image_list = scan_over_image(folder+image_filename)\n",
    "    for local_image in local_image_list:\n",
    "        duplicated_local_image = tf.convert_to_tensor(np.array([local_image for i in range(TTA_runs)]))\n",
    "        augmented_images = test_time_augmentation_layers(duplicated_local_image)\n",
    "        \n",
    "        predictions = model.predict(augmented_images)\n",
    "        localised_predictions.append(np.sum(predictions, axis=0))\n",
    "    \n",
    "    #sum all predictions from all 4 images and retrieve the index of the highest value\n",
    "    global_predictions = np.sum(np.array(localised_predictions),axis=0)\n",
    "    final_prediction = np.argmax(global_predictions)\n",
    "    \n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "papermill": {
     "duration": 6.797562,
     "end_time": "2021-01-06T05:19:45.286327",
     "exception": false,
     "start_time": "2021-01-06T05:19:38.488765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_predictions_over_image_list(image_list, folder):\n",
    "    predictions = []\n",
    "    with tqdm(total=len(image_list)) as pbar:\n",
    "        for image_filename in image_list:\n",
    "            pbar.update(1)\n",
    "            predictions.append(predict_and_vote(image_filename, folder))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "papermill": {
     "duration": 1753.205626,
     "end_time": "2021-01-06T05:49:17.417311",
     "exception": false,
     "start_time": "2021-01-06T05:20:04.211685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4280/4280 [17:48<00:00,  4.01it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_df[\"results\"] = run_predictions_over_image_list(validation_df[\"image_id\"], training_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>filepath</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10234</th>\n",
       "      <td>2824543301.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4763</th>\n",
       "      <td>184909120.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>2602456265.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>1331491784.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17431</th>\n",
       "      <td>414363375.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label  \\\n",
       "10234  2824543301.jpg      3   \n",
       "4763    184909120.jpg      3   \n",
       "9062   2602456265.jpg      3   \n",
       "1874   1331491784.jpg      3   \n",
       "17431   414363375.jpg      3   \n",
       "\n",
       "                                                filepath  results  \n",
       "10234  ../input/cassava-leaf-disease-classification/t...        3  \n",
       "4763   ../input/cassava-leaf-disease-classification/t...        3  \n",
       "9062   ../input/cassava-leaf-disease-classification/t...        3  \n",
       "1874   ../input/cassava-leaf-disease-classification/t...        3  \n",
       "17431  ../input/cassava-leaf-disease-classification/t...        3  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "papermill": {
     "duration": 9.111638,
     "end_time": "2021-01-06T05:50:08.717378",
     "exception": false,
     "start_time": "2021-01-06T05:49:59.605740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.41121495327103%\n"
     ]
    }
   ],
   "source": [
    "true_positives = 0\n",
    "prediction_distribution_per_class = {\"0\":{\"0\": 0, \"1\": 0, \"2\":0, \"3\":0, \"4\":0},\n",
    "                                     \"1\":{\"0\": 0, \"1\": 0, \"2\":0, \"3\":0, \"4\":0},\n",
    "                                     \"2\":{\"0\": 0, \"1\": 0, \"2\":0, \"3\":0, \"4\":0},\n",
    "                                     \"3\":{\"0\": 0, \"1\": 0, \"2\":0, \"3\":0, \"4\":0},\n",
    "                                     \"4\":{\"0\": 0, \"1\": 0, \"2\":0, \"3\":0, \"4\":0}}\n",
    "number_of_images = len(validation_df)\n",
    "for idx, pred in validation_df.iterrows():\n",
    "    if int(pred[\"label\"]) == pred.results:\n",
    "        true_positives+=1\n",
    "    prediction_distribution_per_class[str(pred[\"label\"])][str(pred.results)] += 1\n",
    "print(\"accuracy: {}%\".format(true_positives/number_of_images*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "papermill": {
     "duration": 8.33189,
     "end_time": "2021-01-06T05:51:15.720645",
     "exception": false,
     "start_time": "2021-01-06T05:51:07.388755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_folder = '../input/cassava-leaf-disease-classification/test_images/'\n",
    "submission_df = pd.DataFrame(columns={\"image_id\",\"label\"})\n",
    "submission_df[\"image_id\"] =  os.listdir(test_folder)\n",
    "submission_df[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "papermill": {
     "duration": 8.656135,
     "end_time": "2021-01-06T05:51:32.254653",
     "exception": false,
     "start_time": "2021-01-06T05:51:23.598518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "submission_df[\"label\"] = run_predictions_over_image_list(submission_df[\"image_id\"], test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T05:52:06.161219Z",
     "iopub.status.busy": "2021-01-06T05:52:06.160210Z",
     "iopub.status.idle": "2021-01-06T05:52:06.585388Z",
     "shell.execute_reply": "2021-01-06T05:52:06.586837Z"
    },
    "papermill": {
     "duration": 9.750634,
     "end_time": "2021-01-06T05:52:06.587062",
     "exception": false,
     "start_time": "2021-01-06T05:51:56.836428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "duration": 13065.254265,
   "end_time": "2021-01-06T05:52:32.400246",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-06T02:14:47.145981",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
