{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.664524,
     "end_time": "2020-11-23T13:32:47.332411",
     "exception": false,
     "start_time": "2020-11-23T13:32:46.667887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "package_paths = [\n",
    "    '../input/pytorch-image-models/pytorch-image-models-master', #'../input/efficientnet-pytorch-07/efficientnet_pytorch-0.7.0'\n",
    "    '../input/image-fmix/FMix-master'\n",
    "]\n",
    "import sys; \n",
    "\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "    \n",
    "# from fmix import sample_mask, make_low_freq_image, binarise_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 2.173722,
     "end_time": "2020-11-23T13:32:49.521795",
     "exception": false,
     "start_time": "2020-11-23T13:32:47.348073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import cv2\n",
    "import pydicom\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from catalyst.data.sampler import BalanceClassSampler\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.layers import AdaptiveConcatPool2d, Flatten, Mish\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21397, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../input/cassava-leaf-disease-classification/train.csv').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.057123,
     "end_time": "2020-11-23T13:32:49.643710",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.586587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n",
    "train['path'] = '../input/cassava-leaf-disease-classification/train_images/' + train['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/train_images/1000015157.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/train_images/1000201771.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/train_images/100042118.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/train_images/1000723321.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/train_images/1000812911.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label  \\\n",
       "0  1000015157.jpg      0   \n",
       "1  1000201771.jpg      3   \n",
       "2   100042118.jpg      1   \n",
       "3  1000723321.jpg      1   \n",
       "4  1000812911.jpg      3   \n",
       "\n",
       "                                                                       path  \n",
       "0  ../input/cassava-leaf-disease-classification/train_images/1000015157.jpg  \n",
       "1  ../input/cassava-leaf-disease-classification/train_images/1000201771.jpg  \n",
       "2   ../input/cassava-leaf-disease-classification/train_images/100042118.jpg  \n",
       "3  ../input/cassava-leaf-disease-classification/train_images/1000723321.jpg  \n",
       "4  ../input/cassava-leaf-disease-classification/train_images/1000812911.jpg  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 371.20it/s]\n"
     ]
    }
   ],
   "source": [
    "path_ = '../input/cassava-disease/train'\n",
    "data2019 = []\n",
    "for label in tqdm(os.listdir(path_)):\n",
    "    for file in os.listdir(f'{path_}/{label}'):\n",
    "        data2019.append({'image_id':file, 'label':label, 'path':f'{path_}/{label}/{file}'})\n",
    "data2019 = pd.DataFrame(data2019)\n",
    "data2019['label'] = data2019['label'].replace({'cmd':3, 'cgm':2, 'cbsd':1, 'cbb':0, 'healthy':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5656, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2019.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train-cbb-0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/cassava-disease/train/cbb/train-cbb-0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train-cbb-1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/cassava-disease/train/cbb/train-cbb-1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-cbb-10.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/cassava-disease/train/cbb/train-cbb-10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train-cbb-100.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/cassava-disease/train/cbb/train-cbb-100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train-cbb-101.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/cassava-disease/train/cbb/train-cbb-101.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id  label  \\\n",
       "0    train-cbb-0.jpg      0   \n",
       "1    train-cbb-1.jpg      0   \n",
       "2   train-cbb-10.jpg      0   \n",
       "3  train-cbb-100.jpg      0   \n",
       "4  train-cbb-101.jpg      0   \n",
       "\n",
       "                                                   path  \n",
       "0    ../input/cassava-disease/train/cbb/train-cbb-0.jpg  \n",
       "1    ../input/cassava-disease/train/cbb/train-cbb-1.jpg  \n",
       "2   ../input/cassava-disease/train/cbb/train-cbb-10.jpg  \n",
       "3  ../input/cassava-disease/train/cbb/train-cbb-100.jpg  \n",
       "4  ../input/cassava-disease/train/cbb/train-cbb-101.jpg  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/train_images/1000015157.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/train_images/1000201771.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/train_images/100042118.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/train_images/1000723321.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/cassava-leaf-disease-classification/train_images/1000812911.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label  \\\n",
       "0  1000015157.jpg      0   \n",
       "1  1000201771.jpg      3   \n",
       "2   100042118.jpg      1   \n",
       "3  1000723321.jpg      1   \n",
       "4  1000812911.jpg      3   \n",
       "\n",
       "                                                                       path  \n",
       "0  ../input/cassava-leaf-disease-classification/train_images/1000015157.jpg  \n",
       "1  ../input/cassava-leaf-disease-classification/train_images/1000201771.jpg  \n",
       "2   ../input/cassava-leaf-disease-classification/train_images/100042118.jpg  \n",
       "3  ../input/cassava-leaf-disease-classification/train_images/1000723321.jpg  \n",
       "4  ../input/cassava-leaf-disease-classification/train_images/1000812911.jpg  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train, data2019], axis= 0).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27053it [02:03, 219.44it/s]\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for idx, row in tqdm(train.iterrows(), total = train.shape[0]):\n",
    "    img = cv2.imread(row['path'])\n",
    "    lst.append({'width':img.shape[0], 'height':img.shape[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, pd.DataFrame(lst)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dataset'] = train['path'].apply(lambda x: 'cassava-leaf-disease-classification' if 'cassava-leaf-disease-classification' in x else 'cassava-disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cassava-leaf-disease-classification    21397\n",
       "cassava-disease                         5628\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['width']>=500)&(train['height']>=500)]['dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['width']>=500)&(train['height']>=500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    oof_df = pd.read_pickle('oof_df.pickle')\n",
    "    noisy_images = list(set(oof_df[oof_df['log_loss']>1].image_id.tolist())&set(oof_df[oof_df['euclidean']>np.quantile(oof_df['euclidean'], .95)].image_id.tolist()))\n",
    "    keep = train[~train['image_id'].isin(noisy_images)].reset_index(False)\n",
    "    removed = train[train['image_id'].isin(noisy_images)].reset_index(False)\n",
    "    print(df.shape[0], keep.shape[0], removed.shape[0])\n",
    "    return keep, removed\n",
    "\n",
    "\n",
    "def clean_data(df):\n",
    "    path_ = 'baseline_pytorch_efb4'\n",
    "    oof_df = pd.DataFrame()\n",
    "    for oof_pkl in [f'{path_}/{f}' for f in os.listdir(path_) if 'pkl' in f]:\n",
    "        oof_df = pd.concat([oof_df, pd.read_pickle(oof_pkl)], axis=0)\n",
    "    oof_df = oof_df.reset_index(False)\n",
    "    oof_df['confidence'] = oof_df[['label']+[f'soft_label_{i}' for i in range(1,6)]].apply(lambda x: 1-x[int(x[0]+1)], axis=1)\n",
    "    noisy_images = list(set(oof_df[oof_df['confidence']>.98].image_id.tolist()))\n",
    "    keep = df[~df['image_id'].isin(noisy_images)].reset_index(False)\n",
    "    removed = df[df['image_id'].isin(noisy_images)].reset_index(False)\n",
    "    print(df.shape[0], keep.shape[0], removed.shape[0])\n",
    "    return keep, removed\n",
    "\n",
    "# def clean_data(df):\n",
    "#     keep = df.sample(int(df.shape[0]*.99)).reset_index(False)\n",
    "#     removed = df[~df['image_id'].isin(keep.image_id.tolist())].reset_index(False)\n",
    "#     print(df.shape[0], keep.shape[0], removed.shape[0])\n",
    "#     return keep, removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, removed = clean_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 719,\n",
    "    'model_arch': 'tf_efficientnet_b4_ns',#'tf_efficientnet_b4_ns',\n",
    "    'img_size': 500,#512\n",
    "    'epochs': 10,\n",
    "    'train_bs': 4,#16,\n",
    "    'valid_bs': 4,#32,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'weight_decay':1e-6,\n",
    "    'num_workers': 0, #4\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'freeze_bn_epochs':5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015931,
     "end_time": "2020-11-23T13:32:49.801027",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.785096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "papermill": {
     "duration": 0.315262,
     "end_time": "2020-11-23T13:32:50.132792",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.817530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021311,
     "end_time": "2020-11-23T13:32:50.174973",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.153662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "papermill": {
     "duration": 0.064816,
     "end_time": "2020-11-23T13:32:50.261340",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.196524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[0]\n",
    "    H = size[1]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "        \n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, \n",
    "                 transforms=None, \n",
    "                 output_label=True, \n",
    "                 one_hot_label=False,\n",
    "                 do_fmix=False, \n",
    "                 fmix_params={\n",
    "                     'alpha': 1., \n",
    "                     'decay_power': 3., \n",
    "                     'shape': (CFG['img_size'], CFG['img_size']),\n",
    "                     'max_soft': True, \n",
    "                     'reformulate': False\n",
    "                 },\n",
    "                 do_cutmix=False,\n",
    "                 cutmix_params={\n",
    "                     'alpha': 1,\n",
    "                 }\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.do_fmix = do_fmix\n",
    "        self.fmix_params = fmix_params\n",
    "        self.do_cutmix = do_cutmix\n",
    "        self.cutmix_params = cutmix_params\n",
    "        \n",
    "        self.output_label = output_label\n",
    "        self.one_hot_label = one_hot_label\n",
    "        \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "            #print(self.labels)\n",
    "            \n",
    "            if one_hot_label is True:\n",
    "                self.labels = np.eye(self.df['label'].max()+1)[self.labels]\n",
    "                #print(self.labels)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "          \n",
    "        img  = get_img(\"{}\".format(self.df.loc[index]['path']))\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        if self.do_fmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n",
    "            with torch.no_grad():\n",
    "                #lam, mask = sample_mask(**self.fmix_params)\n",
    "                \n",
    "                lam = np.clip(np.random.beta(self.fmix_params['alpha'], self.fmix_params['alpha']),0.6,0.7)\n",
    "                \n",
    "                # Make mask, get mean / std\n",
    "                mask = make_low_freq_image(self.fmix_params['decay_power'], self.fmix_params['shape'])\n",
    "                mask = binarise_mask(mask, lam, self.fmix_params['shape'], self.fmix_params['max_soft'])\n",
    "    \n",
    "                fmix_ix = np.random.choice(self.df.index, size=1)[0]\n",
    "                fmix_img  = get_img(\"{}\".format(self.df.iloc[fmix_ix]['path']))\n",
    "\n",
    "                if self.transforms:\n",
    "                    fmix_img = self.transforms(image=fmix_img)['image']\n",
    "\n",
    "                mask_torch = torch.from_numpy(mask)\n",
    "                \n",
    "                # mix image\n",
    "                img = mask_torch*img+(1.-mask_torch)*fmix_img\n",
    "\n",
    "                #print(mask.shape)\n",
    "\n",
    "                #assert self.output_label==True and self.one_hot_label==True\n",
    "\n",
    "                # mix target\n",
    "                rate = mask.sum()/CFG['img_size']/CFG['img_size']\n",
    "                target = rate*target + (1.-rate)*self.labels[fmix_ix]\n",
    "                #print(target, mask, img)\n",
    "                #assert False\n",
    "        \n",
    "        if self.do_cutmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n",
    "            #print(img.sum(), img.shape)\n",
    "            with torch.no_grad():\n",
    "                cmix_ix = np.random.choice(self.df.index, size=1)[0]\n",
    "                cmix_img  = get_img(\"{}\".format(self.df.iloc[cmix_ix]['path']))\n",
    "                if self.transforms:\n",
    "                    cmix_img = self.transforms(image=cmix_img)['image']\n",
    "                    \n",
    "                lam = np.clip(np.random.beta(self.cutmix_params['alpha'], self.cutmix_params['alpha']),0.3,0.4)\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox((CFG['img_size'], CFG['img_size']), lam)\n",
    "\n",
    "                img[:, bbx1:bbx2, bby1:bby2] = cmix_img[:, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "                rate = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (CFG['img_size'] * CFG['img_size']))\n",
    "                target = rate*target + (1.-rate)*self.labels[cmix_ix]\n",
    "                \n",
    "            #print('-', img.sum())\n",
    "            #print(target)\n",
    "            #assert False\n",
    "                            \n",
    "        # do label smoothing\n",
    "        #print(type(img), type(target))\n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02183,
     "end_time": "2020-11-23T13:32:50.304795",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.282965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Train\\Validation Image Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "papermill": {
     "duration": 0.590042,
     "end_time": "2020-11-23T13:32:50.916225",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.326183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "#             HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "#             RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            CoarseDropout(p=0.5),\n",
    "            Cutout(p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "  \n",
    "        \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            Resize(CFG['img_size'], CFG['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024452,
     "end_time": "2020-11-23T13:32:50.962106",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.937654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "papermill": {
     "duration": 0.033239,
     "end_time": "2020-11-23T13:32:51.017593",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.984354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     def __init__(self, arch='resnext50_32x4d_ssl', n=6, pre=True):\n",
    "#         super().__init__()\n",
    "#         m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n",
    "#         self.enc = nn.Sequential(*list(m.children())[:-2])       \n",
    "#         nc = list(m.children())[-1].in_features\n",
    "#         self.head = nn.Sequential(AdaptiveConcatPool2d(),Flatten(),nn.Linear(2*nc,512),\n",
    "#                             Mish(),nn.BatchNorm1d(512), nn.Dropout(0.5),nn.Linear(512,n))\n",
    "        \n",
    "#     def forward(self, *x):\n",
    "#         shape = x[0].shape\n",
    "#         n = len(x)\n",
    "#         x = torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n",
    "#         #x: bs*N x 3 x 128 x 128\n",
    "#         x = self.enc(x)\n",
    "#         #x: bs*N x C x 4 x 4\n",
    "#         shape = x.shape\n",
    "#         #concatenate the output for tiles into a single map\n",
    "#         x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n",
    "#           .view(-1,shape[1],shape[2]*n,shape[3])\n",
    "#         #x: bs x C x N*4 x 4\n",
    "#         x = self.head(x)\n",
    "#         #x: bs x n\n",
    "#         return x\n",
    "    \n",
    "\n",
    "# class CassvaImgClassifier(nn.Module):\n",
    "#     def __init__(self, model_arch, n_class, pretrained=False):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "#         n_features = self.model.classifier.in_features\n",
    "#         self.enc = nn.Sequential(*list(self.model.children())[:-2])\n",
    "# #         self.model.classifier = nn.Linear(n_features, n_class)\n",
    "#         self.head = nn.Sequential(AdaptiveConcatPool2d(),\n",
    "#                                               Flatten(),\n",
    "#                                               nn.Linear(2*n_features,512),\n",
    "#                                               Mish(),\n",
    "#                                               nn.BatchNorm1d(512), \n",
    "#                                               nn.Dropout(0.5),\n",
    "#                                               nn.Linear(512,n_class))\n",
    "            \n",
    "#         '''\n",
    "#         self.model.classifier = nn.Sequential(\n",
    "#             nn.Dropout(0.3),\n",
    "#             #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n",
    "#             nn.Linear(n_features, n_class, bias=True)\n",
    "#         )\n",
    "#         '''\n",
    "#     def forward(self, x):\n",
    "    \n",
    "#         shape = x.shape\n",
    "#         n = 1\n",
    "#         x = x.view(-1,shape[1],shape[2],shape[3])\n",
    "#         #x: bs*N x 3 x 128 x 128\n",
    "#         x = self.enc(x)\n",
    "#         #x: bs*N x C x 4 x 4\n",
    "#         shape = x.shape\n",
    "#         #concatenate the output for tiles into a single map\n",
    "#         x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous().view(-1,shape[1],shape[2]*n,shape[3])\n",
    "#         #x: bs x C x N*4 x 4\n",
    "#         x = self.head(x)\n",
    "#         #x: bs x n\n",
    "#         return x\n",
    "class AddGaussianNoise(nn.Module):\n",
    "    def __init__(self, mean=0., std=.1):\n",
    "        super().__init__()\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def forward(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size(), device=CFG['device']) * self.std + self.mean\n",
    "        \n",
    "#     def __call__(self, tensor):\n",
    "#         return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "#     def __repr__(self):\n",
    "#         return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)    \n",
    "\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        num_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            AddGaussianNoise(),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "#         self.enc = nn.Sequential(*list(self.model.children())[:-1])\n",
    "#         self.noise = AddGaussianNoise()\n",
    "#         self.classifier = nn.Linear(n_features, n_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x    \n",
    "    \n",
    "# ====================================================\n",
    "# ResNext Model\n",
    "# ====================================================\n",
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_arch, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        #='resnext50_32x4d',\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            AddGaussianNoise(),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "#         self.model.fc = nn.Linear(n_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class CustomViT(nn.Module):\n",
    "    def __init__(self, model_arch, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        ### vit\n",
    "        num_features = self.model.head.in_features\n",
    "        self.model.head = nn.Sequential(\n",
    "            AddGaussianNoise(),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "        '''\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            #nn.Linear(num_features, hidden_size,bias=True), nn.ELU(),\n",
    "            nn.Linear(num_features, num_classes, bias=True)\n",
    "        )\n",
    "        '''\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CustomViT\n",
    "# CFG = {\n",
    "#     'fold_num': 5,\n",
    "#     'seed': 719,\n",
    "#     'model_arch': 'vit_base_patch16_384',#'tf_efficientnet_b4_ns',\n",
    "#     'img_size': 384,\n",
    "#     'epochs': 10,\n",
    "#     'train_bs': 4,#16,\n",
    "#     'valid_bs': 4,#32,\n",
    "#     'T_0': 10,\n",
    "#     'lr': 1e-4,\n",
    "#     'min_lr': 1e-6,\n",
    "#     'weight_decay':1e-6,\n",
    "#     'num_workers': 0, #4\n",
    "#     'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "#     'verbose_step': 1,\n",
    "#     'device': 'cuda:0',\n",
    "#     'freeze_bn_epochs':5,\n",
    "# }\n",
    "\n",
    "# #CassvaImgClassifier\n",
    "# CFG = {\n",
    "#     'fold_num': 5,\n",
    "#     'seed': 719,\n",
    "#     'model_arch': 'vit_base_patch16_384',#'tf_efficientnet_b4_ns',\n",
    "#     'img_size': 512,\n",
    "#     'epochs': 10,\n",
    "#     'train_bs': 4,#16,\n",
    "#     'valid_bs': 4,#32,\n",
    "#     'T_0': 10,\n",
    "#     'lr': 1e-4,\n",
    "#     'min_lr': 1e-6,\n",
    "#     'weight_decay':1e-6,\n",
    "#     'num_workers': 0, #4\n",
    "#     'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "#     'verbose_step': 1,\n",
    "#     'device': 'cuda:0',\n",
    "#     'freeze_bn_epochs':5,\n",
    "# }\n",
    "\n",
    "# #CustomResNext\n",
    "# CFG = {\n",
    "#     'fold_num': 5,\n",
    "#     'seed': 719,\n",
    "#     'model_arch': 'resnext50_32x4d',#'tf_efficientnet_b4_ns',\n",
    "#     'img_size': 512,\n",
    "#     'epochs': 10,\n",
    "#     'train_bs': 4,#16,\n",
    "#     'valid_bs': 4,#32,\n",
    "#     'T_0': 10,\n",
    "#     'lr': 1e-4,\n",
    "#     'min_lr': 1e-6,\n",
    "#     'weight_decay':1e-6,\n",
    "#     'num_workers': 0, #4\n",
    "#     'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "#     'verbose_step': 1,\n",
    "#     'device': 'cuda:0',\n",
    "#     'freeze_bn_epochs':5,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021054,
     "end_time": "2020-11-23T13:32:51.059722",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.038668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "papermill": {
     "duration": 0.061685,
     "end_time": "2020-11-23T13:32:51.144150",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.082465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "        \n",
    "    train_ds = CassavaDataset(train_, transforms=get_train_transforms(), output_label=True, one_hot_label=False, do_fmix=False, do_cutmix=False)\n",
    "    valid_ds = CassavaDataset(valid_, transforms=get_valid_transforms(), output_label=True)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        shuffle=True,        \n",
    "        num_workers=CFG['num_workers'],\n",
    "        #sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"downsampling\")\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n",
    "    model.train()\n",
    "\n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "\n",
    "        #print(image_labels.shape, exam_label.shape)\n",
    "        with autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "            #print(image_preds.shape, exam_pred.shape)\n",
    "\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01\n",
    "\n",
    "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n",
    "\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                if scheduler is not None and schd_batch_update:\n",
    "                    scheduler.step()\n",
    "\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                \n",
    "                pbar.set_description(description)\n",
    "                \n",
    "    if scheduler is not None and not schd_batch_update:\n",
    "        scheduler.step()\n",
    "        \n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        #print(image_preds.shape, exam_pred.shape)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]  \n",
    "\n",
    "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
    "            description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "            pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    validated_accuracy = (image_preds_all==image_targets_all).mean()\n",
    "    print('validation multi-class accuracy = {:.4f}'.format(validated_accuracy))\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        if schd_loss_update:\n",
    "            scheduler.step(loss_sum/sample_num)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "    return validated_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "papermill": {
     "duration": 0.034873,
     "end_time": "2020-11-23T13:32:51.200704",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.165831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reference: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/173733\n",
    "class MyCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean'):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"\n",
    "    NLL loss with label smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        \"\"\"\n",
    "        Constructor for the LabelSmoothing module.\n",
    "        :param smoothing: label smoothing factor\n",
    "        \"\"\"\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        assert smoothing < 1.0\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1. - smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = F.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "    \n",
    "    \n",
    "def bi_tempered_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing=0.0,\n",
    "        num_iters=5,\n",
    "        reduction = 'mean'):\n",
    "\n",
    "    \"\"\"Bi-Tempered Logistic Loss.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      labels: A tensor with shape and dtype as activations (onehot), \n",
    "        or a long tensor of one dimension less than activations (pytorch standard)\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing parameter between [0, 1). Default 0.0.\n",
    "      num_iters: Number of iterations to run the method. Default 5.\n",
    "      reduction: ``'none'`` | ``'mean'`` | ``'sum'``. Default ``'mean'``.\n",
    "        ``'none'``: No reduction is applied, return shape is shape of\n",
    "        activations without the last dimension.\n",
    "        ``'mean'``: Loss is averaged over minibatch. Return shape (1,)\n",
    "        ``'sum'``: Loss is summed over minibatch. Return shape (1,)\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(labels.shape)<len(activations.shape): #not one-hot\n",
    "        labels_onehot = torch.zeros_like(activations)\n",
    "        labels_onehot.scatter_(1, labels[..., None], 1)\n",
    "    else:\n",
    "        labels_onehot = labels\n",
    "\n",
    "    if label_smoothing > 0:\n",
    "        num_classes = labels_onehot.shape[-1]\n",
    "        labels_onehot = ( 1 - label_smoothing * num_classes / (num_classes - 1) ) \\\n",
    "                * labels_onehot + \\\n",
    "                label_smoothing / (num_classes - 1)\n",
    "\n",
    "    probabilities = tempered_softmax(activations, t2, num_iters)\n",
    "\n",
    "    loss_values = labels_onehot * log_t(labels_onehot + 1e-10, t1) \\\n",
    "            - labels_onehot * log_t(probabilities, t1) \\\n",
    "            - labels_onehot.pow(2.0 - t1) / (2.0 - t1) \\\n",
    "            + probabilities.pow(2.0 - t1) / (2.0 - t1)\n",
    "    loss_values = loss_values.sum(dim = -1) #sum over classes\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return loss_values\n",
    "    if reduction == 'sum':\n",
    "        return loss_values.sum()\n",
    "    if reduction == 'mean':\n",
    "        return loss_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cassava-leaf-disease-classification    21397\n",
       "cassava-disease                         5628\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020806,
     "end_time": "2020-11-23T13:32:51.243006",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.222200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 8602.016415,
     "end_time": "2020-11-23T15:56:13.280909",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.264494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4548: 100%|██████████| 1352/1352 [01:37<00:00, 13.87it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7265: 100%|██████████| 5405/5405 [16:00<00:00,  5.63it/s]\n",
      "epoch 1 loss: 0.4534: 100%|██████████| 1352/1352 [01:38<00:00, 13.79it/s]\n",
      "epoch 2 loss: 0.7439:   0%|          | 1/5405 [00:00<13:06,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.6927: 100%|██████████| 5405/5405 [15:51<00:00,  5.68it/s]\n",
      "epoch 3 loss: 0.6737: 100%|██████████| 5405/5405 [15:38<00:00,  5.76it/s]\n",
      "epoch 3 loss: 0.4423: 100%|██████████| 1352/1352 [01:35<00:00, 14.16it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.3986: 100%|██████████| 1352/1352 [01:34<00:00, 14.24it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.3714: 100%|██████████| 1352/1352 [01:35<00:00, 14.21it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.6405: 100%|██████████| 5405/5405 [15:59<00:00,  5.64it/s]\n",
      "epoch 7 loss: 0.3866: 100%|██████████| 1352/1352 [01:39<00:00, 13.62it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.5671: 100%|██████████| 5405/5405 [16:12<00:00,  5.56it/s]\n",
      "epoch 9 loss: 0.3808: 100%|██████████| 1352/1352 [01:40<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8931\n",
      "Training with 1 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.4605: 100%|██████████| 1352/1352 [01:37<00:00, 13.93it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7698:  11%|█         | 590/5405 [01:45<15:14,  5.26it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 1 loss: 0.4179: 100%|██████████| 1352/1352 [01:36<00:00, 13.96it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.3969: 100%|██████████| 1352/1352 [01:36<00:00, 14.01it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.4351: 100%|██████████| 1352/1352 [01:39<00:00, 13.60it/s]\n",
      "epoch 4 loss: 0.4138:   0%|          | 1/5405 [00:00<13:44,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.6617: 100%|██████████| 5405/5405 [16:04<00:00,  5.60it/s]\n",
      "epoch 5 loss: 0.6750: 100%|██████████| 5405/5405 [16:03<00:00,  5.61it/s]\n",
      "epoch 5 loss: 0.4268:  64%|██████▍   | 870/1352 [01:03<00:35, 13.57it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 6 loss: 0.3933: 100%|██████████| 1352/1352 [01:37<00:00, 13.84it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.5958: 100%|██████████| 5405/5405 [16:08<00:00,  5.58it/s]\n",
      "epoch 7 loss: 0.4087: 100%|██████████| 1352/1352 [01:39<00:00, 13.63it/s]\n",
      "epoch 8 loss: 0.8140:   0%|          | 1/5405 [00:00<13:52,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.6039:  86%|████████▌ | 4625/5405 [13:57<02:16,  5.72it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 8 loss: 0.3812: 100%|██████████| 1352/1352 [01:40<00:00, 13.48it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.5881: 100%|██████████| 5405/5405 [16:22<00:00,  5.50it/s]\n",
      "epoch 0 loss: 0.4275: 100%|██████████| 1352/1352 [01:37<00:00, 13.87it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.7063:  11%|█▏        | 609/5405 [01:47<14:01,  5.70it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 1 loss: 0.7556:  52%|█████▏    | 2835/5405 [08:23<07:15,  5.90it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 1 loss: 0.7747:  99%|█████████▉| 5339/5405 [15:48<00:11,  5.64it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 2 loss: 0.6932: 100%|██████████| 5405/5405 [15:51<00:00,  5.68it/s]\n",
      "epoch 2 loss: 0.3901: 100%|██████████| 1352/1352 [01:35<00:00, 14.15it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.7049:  21%|██▏       | 1151/5405 [03:21<12:17,  5.77it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 4 loss: 0.6802:  81%|████████  | 4379/5405 [12:46<02:49,  6.06it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 4 loss: 0.6389: 100%|██████████| 5405/5405 [15:46<00:00,  5.71it/s]\n",
      "epoch 4 loss: 0.3929: 100%|██████████| 1352/1352 [01:35<00:00, 14.16it/s]\n",
      "epoch 5 loss: 0.4587:   0%|          | 1/5405 [00:00<13:23,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.6204:   5%|▍         | 267/5405 [00:46<14:29,  5.91it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 5 loss: 0.4164: 100%|██████████| 1352/1352 [01:35<00:00, 14.12it/s]\n",
      "epoch 6 loss: 0.4170:   0%|          | 1/5405 [00:00<13:55,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.6471: 100%|██████████| 5405/5405 [15:43<00:00,  5.73it/s]\n",
      "epoch 6 loss: 0.3674: 100%|██████████| 1352/1352 [01:35<00:00, 14.14it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.6259: 100%|██████████| 5405/5405 [15:42<00:00,  5.73it/s]\n",
      "epoch 8 loss: 0.3663: 100%|██████████| 1352/1352 [01:36<00:00, 14.08it/s]\n",
      "epoch 9 loss: 0.4117:   0%|          | 1/5405 [00:00<13:17,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.6152: 100%|██████████| 5405/5405 [15:44<00:00,  5.72it/s]\n",
      "epoch 9 loss: 0.3703:  79%|███████▊  | 1062/1352 [01:15<00:20, 14.22it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 0 loss: 0.8289:  53%|█████▎    | 2875/5405 [08:20<07:07,  5.92it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 1 loss: 0.4145: 100%|██████████| 1352/1352 [01:35<00:00, 14.19it/s]\n",
      "  0%|          | 0/5405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.6782: 100%|██████████| 5405/5405 [15:45<00:00,  5.72it/s]\n",
      "epoch 4 loss: 0.6545:  41%|████      | 2224/5405 [06:28<09:57,  5.32it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 4 loss: 0.4127: 100%|██████████| 1352/1352 [01:34<00:00, 14.32it/s]\n",
      "epoch 5 loss: 0.4473:   0%|          | 1/5405 [00:00<14:38,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.6555: 100%|██████████| 5405/5405 [15:41<00:00,  5.74it/s]\n",
      "epoch 6 loss: 0.6381: 100%|██████████| 5405/5405 [15:42<00:00,  5.74it/s]\n",
      "epoch 7 loss: 0.6399:  51%|█████▏    | 2782/5405 [08:04<07:57,  5.49it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 7 loss: 0.3888: 100%|██████████| 1352/1352 [01:34<00:00, 14.27it/s]\n",
      "epoch 8 loss: 0.5256:   0%|          | 1/5405 [00:00<13:28,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.5942: 100%|██████████| 5405/5405 [16:07<00:00,  5.58it/s]\n",
      "epoch 0 loss: 0.8087:  78%|███████▊  | 4198/5405 [12:29<03:34,  5.62it/s]"
     ]
    }
   ],
   "source": [
    "################ freeze bn \n",
    "def freeze_batchnorm_stats(net):\n",
    "    try:\n",
    "        for m in net.modules():\n",
    "            if isinstance(m,nn.BatchNorm2d) or isinstance(m,nn.LayerNorm):\n",
    "                m.eval()\n",
    "    except ValuError:\n",
    "        print('error with batchnorm2d or layernorm')\n",
    "        return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     # for training only, need nightly build pytorch\n",
    "\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    valid= []\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        # we'll train fold 0 first\n",
    "#         if fold>0:\n",
    "#             break\n",
    "\n",
    "        print('Training with {} started'.format(fold))\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx)\n",
    "\n",
    "        device = torch.device(CFG['device'])\n",
    "#         device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#         if torch.cuda.is_available():\n",
    "#             map_location=lambda storage, loc: storage.cuda()\n",
    "#         else:\n",
    "#             map_location='cpu'\n",
    "#         print('device ', device)\n",
    "        \n",
    "        model = CassvaImgClassifier(CFG['model_arch'], train.label.nunique(), pretrained=True).to(device)\n",
    "        scaler = GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "        #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.1, step_size=CFG['epochs']-1)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n",
    "        #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=25, \n",
    "        #                                                max_lr=CFG['lr'], epochs=CFG['epochs'], steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        loss_tr = LabelSmoothingCrossEntropy().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "        best_valid_accuracy = 0\n",
    "        for epoch in range(CFG['epochs']):\n",
    "#             if epoch < CFG['freeze_bn_epochs']:\n",
    "#                 freeze_batchnorm_stats(model)  \n",
    "            train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=False)\n",
    "            with torch.no_grad():\n",
    "                valid_accuracy = valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "                if valid_accuracy > best_valid_accuracy:\n",
    "                    best_valid_accuracy = valid_accuracy\n",
    "                    torch.save(model.state_dict(),'{}_fold_{}'.format(CFG['model_arch'], fold))\n",
    "#         torch.save(model.cnn_model.state_dict(),'{}/cnn_model_fold_{}_{}'.format(CFG['model_path'], fold, CFG['tag']))\n",
    "        del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "        torch.cuda.empty_cache()\n",
    "        valid.append(best_valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference fold 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:15<00:00,  1.77it/s]\n",
      "100%|██████████| 134/134 [01:16<00:00,  1.76it/s]\n",
      "100%|██████████| 134/134 [01:16<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 validation loss = 0.34586\n",
      "fold 0 validation accuracy = 0.91402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n",
    "\n",
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 719,\n",
    "    'model_arch': 'tf_efficientnet_b4_ns',\n",
    "    'img_size': 512,\n",
    "    'epochs': 10,\n",
    "    'train_bs': 32,\n",
    "    'valid_bs': 32,\n",
    "    'lr': 1e-4,\n",
    "    'num_workers': 0,\n",
    "    'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'tta': 3,\n",
    "    'weights': [1,1,1,1,1]\n",
    "}\n",
    "\n",
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        \n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all\n",
    "\n",
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     # for training only, need nightly build pytorch\n",
    "\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        # we'll train fold 0 first\n",
    "        if fold>0:\n",
    "            break\n",
    "\n",
    "        print('Inference fold {} started'.format(fold))\n",
    "\n",
    "        valid_ = train.loc[val_idx,:].reset_index(drop=True)\n",
    "        valid_ds = CassavaDataset(valid_, '../input/cassava-leaf-disease-classification/train_images/', transforms=get_inference_transforms(), output_label=False)\n",
    "        \n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            valid_ds, \n",
    "            batch_size=CFG['valid_bs'],\n",
    "            num_workers=CFG['num_workers'],\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "        )\n",
    "\n",
    "        device = torch.device(CFG['device'])\n",
    "        model = CassvaImgClassifier(CFG['model_arch'], train.label.nunique()).to(device)\n",
    "        \n",
    "        val_preds = []\n",
    "        \n",
    "        #for epoch in range(CFG['epochs']-3):    \n",
    "        model.load_state_dict(torch.load('{}_fold_{}'.format(CFG['model_arch'], fold)))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(CFG['tta']):\n",
    "                val_preds += [1/CFG['tta']*inference_one_epoch(model, val_loader, device)]\n",
    "                \n",
    "        val_preds = np.mean(val_preds, axis=0) \n",
    "        \n",
    "        \n",
    "        print('fold {} validation loss = {:.5f}'.format(fold, log_loss(valid_.label.values, val_preds)))\n",
    "        print('fold {} validation accuracy = {:.5f}'.format(fold, (valid_.label.values==np.argmax(val_preds, axis=1)).mean()))\n",
    "        \n",
    "        oof_ = pd.concat([valid_, pd.DataFrame(val_preds, columns=[f'soft_label_{i}' for i in range(1,6)])], axis=1)\n",
    "        oof_.to_pickle(f\"{CFG['model_arch']}_oof{fold}.pkl\")\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-64-53e7ad4baecf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-64-53e7ad4baecf>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    v1 baseline accuracy = 0.8857\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "v1 baseline accuracy = 0.8857\n",
    "v2 v1=> change LabelSmoothingCrossEntropy accuracy = 0.8874\n",
    "v3 v2=> add freeze_batchnorm_stats accuracy = 0.8874 no change\n",
    "v4 v2=> remove some aug accuracy = 0.8937\n",
    "v5 v4=> use ViT accuracy = 0.8837\n",
    "v6 v4=> use resnext accuracy = 0.8734\n",
    "v7 v4=> only classify 0,1,2,4 cause 3 is too much accuracy = 0.85\n",
    "v8 v4=> remove noisy image by oof accuracy = 0.93\n",
    "v9 v4=> remove noisy by confidence \n",
    "v10 v4=> remove noisy by confidence \n",
    "fold 0 validation accuracy = 0.91776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 8.681322,
     "end_time": "2020-11-23T15:56:30.750663",
     "exception": false,
     "start_time": "2020-11-23T15:56:22.069341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inferece part is here: https://www.kaggle.com/khyeh0719/pytorch-efficientnet-baseline-inference-tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "take 0.95 fold 0 validation accuracy = 0.91495\n",
    "confidence 0.95 fold 0 validation accuracy = 0.91776\n",
    "confidence 0.98 fold 0 validation accuracy = 0.91776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "duration": 8637.721674,
   "end_time": "2020-11-23T15:56:40.428882",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-23T13:32:42.707208",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
