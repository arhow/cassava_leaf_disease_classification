{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.664524,
     "end_time": "2020-11-23T13:32:47.332411",
     "exception": false,
     "start_time": "2020-11-23T13:32:46.667887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "package_paths = [\n",
    "    '../input/pytorch-image-models/pytorch-image-models-master', #'../input/efficientnet-pytorch-07/efficientnet_pytorch-0.7.0'\n",
    "    '../input/image-fmix/FMix-master'\n",
    "]\n",
    "import sys; \n",
    "\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "    \n",
    "# from fmix import sample_mask, make_low_freq_image, binarise_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 2.173722,
     "end_time": "2020-11-23T13:32:49.521795",
     "exception": false,
     "start_time": "2020-11-23T13:32:47.348073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import cv2\n",
    "import pydicom\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from catalyst.data.sampler import BalanceClassSampler\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.layers import AdaptiveConcatPool2d, Flatten, Mish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.057123,
     "end_time": "2020-11-23T13:32:49.643710",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.586587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n",
    "submission = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df = pd.read_pickle('oof_df.pickle')\n",
    "noisy_images = list(set(oof_df[oof_df['log_loss']>1].image_id.tolist())&set(oof_df[oof_df['euclidean']>np.quantile(oof_df['euclidean'], .95)].image_id.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[~train['image_id'].isin(noisy_images)].reset_index(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CassvaImgClassifier\n",
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 719,\n",
    "    'model_arch': 'vit_base_patch16_384',#'tf_efficientnet_b4_ns',\n",
    "    'img_size': 512,\n",
    "    'epochs': 10,\n",
    "    'train_bs': 4,#16,\n",
    "    'valid_bs': 4,#32,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'weight_decay':1e-6,\n",
    "    'num_workers': 0, #4\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'freeze_bn_epochs':5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015931,
     "end_time": "2020-11-23T13:32:49.801027",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.785096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "papermill": {
     "duration": 0.315262,
     "end_time": "2020-11-23T13:32:50.132792",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.817530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021311,
     "end_time": "2020-11-23T13:32:50.174973",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.153662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "papermill": {
     "duration": 0.064816,
     "end_time": "2020-11-23T13:32:50.261340",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.196524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[0]\n",
    "    H = size[1]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, data_root, \n",
    "                 transforms=None, \n",
    "                 output_label=True, \n",
    "                 one_hot_label=False,\n",
    "                 do_fmix=False, \n",
    "                 fmix_params={\n",
    "                     'alpha': 1., \n",
    "                     'decay_power': 3., \n",
    "                     'shape': (CFG['img_size'], CFG['img_size']),\n",
    "                     'max_soft': True, \n",
    "                     'reformulate': False\n",
    "                 },\n",
    "                 do_cutmix=False,\n",
    "                 cutmix_params={\n",
    "                     'alpha': 1,\n",
    "                 }\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.do_fmix = do_fmix\n",
    "        self.fmix_params = fmix_params\n",
    "        self.do_cutmix = do_cutmix\n",
    "        self.cutmix_params = cutmix_params\n",
    "        \n",
    "        self.output_label = output_label\n",
    "        self.one_hot_label = one_hot_label\n",
    "        \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "            #print(self.labels)\n",
    "            \n",
    "            if one_hot_label is True:\n",
    "                self.labels = np.eye(self.df['label'].max()+1)[self.labels]\n",
    "                #print(self.labels)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "          \n",
    "        img  = get_img(\"{}/{}\".format(self.data_root, self.df.loc[index]['image_id']))\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        if self.do_fmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n",
    "            with torch.no_grad():\n",
    "                #lam, mask = sample_mask(**self.fmix_params)\n",
    "                \n",
    "                lam = np.clip(np.random.beta(self.fmix_params['alpha'], self.fmix_params['alpha']),0.6,0.7)\n",
    "                \n",
    "                # Make mask, get mean / std\n",
    "                mask = make_low_freq_image(self.fmix_params['decay_power'], self.fmix_params['shape'])\n",
    "                mask = binarise_mask(mask, lam, self.fmix_params['shape'], self.fmix_params['max_soft'])\n",
    "    \n",
    "                fmix_ix = np.random.choice(self.df.index, size=1)[0]\n",
    "                fmix_img  = get_img(\"{}/{}\".format(self.data_root, self.df.iloc[fmix_ix]['image_id']))\n",
    "\n",
    "                if self.transforms:\n",
    "                    fmix_img = self.transforms(image=fmix_img)['image']\n",
    "\n",
    "                mask_torch = torch.from_numpy(mask)\n",
    "                \n",
    "                # mix image\n",
    "                img = mask_torch*img+(1.-mask_torch)*fmix_img\n",
    "\n",
    "                #print(mask.shape)\n",
    "\n",
    "                #assert self.output_label==True and self.one_hot_label==True\n",
    "\n",
    "                # mix target\n",
    "                rate = mask.sum()/CFG['img_size']/CFG['img_size']\n",
    "                target = rate*target + (1.-rate)*self.labels[fmix_ix]\n",
    "                #print(target, mask, img)\n",
    "                #assert False\n",
    "        \n",
    "        if self.do_cutmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n",
    "            #print(img.sum(), img.shape)\n",
    "            with torch.no_grad():\n",
    "                cmix_ix = np.random.choice(self.df.index, size=1)[0]\n",
    "                cmix_img  = get_img(\"{}/{}\".format(self.data_root, self.df.iloc[cmix_ix]['image_id']))\n",
    "                if self.transforms:\n",
    "                    cmix_img = self.transforms(image=cmix_img)['image']\n",
    "                    \n",
    "                lam = np.clip(np.random.beta(self.cutmix_params['alpha'], self.cutmix_params['alpha']),0.3,0.4)\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox((CFG['img_size'], CFG['img_size']), lam)\n",
    "\n",
    "                img[:, bbx1:bbx2, bby1:bby2] = cmix_img[:, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "                rate = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (CFG['img_size'] * CFG['img_size']))\n",
    "                target = rate*target + (1.-rate)*self.labels[cmix_ix]\n",
    "                \n",
    "            #print('-', img.sum())\n",
    "            #print(target)\n",
    "            #assert False\n",
    "                            \n",
    "        # do label smoothing\n",
    "        #print(type(img), type(target))\n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02183,
     "end_time": "2020-11-23T13:32:50.304795",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.282965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Train\\Validation Image Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "papermill": {
     "duration": 0.590042,
     "end_time": "2020-11-23T13:32:50.916225",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.326183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "#             HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "#             RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            CoarseDropout(p=0.5),\n",
    "            Cutout(p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "  \n",
    "        \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            Resize(CFG['img_size'], CFG['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024452,
     "end_time": "2020-11-23T13:32:50.962106",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.937654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "papermill": {
     "duration": 0.033239,
     "end_time": "2020-11-23T13:32:51.017593",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.984354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     def __init__(self, arch='resnext50_32x4d_ssl', n=6, pre=True):\n",
    "#         super().__init__()\n",
    "#         m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n",
    "#         self.enc = nn.Sequential(*list(m.children())[:-2])       \n",
    "#         nc = list(m.children())[-1].in_features\n",
    "#         self.head = nn.Sequential(AdaptiveConcatPool2d(),Flatten(),nn.Linear(2*nc,512),\n",
    "#                             Mish(),nn.BatchNorm1d(512), nn.Dropout(0.5),nn.Linear(512,n))\n",
    "        \n",
    "#     def forward(self, *x):\n",
    "#         shape = x[0].shape\n",
    "#         n = len(x)\n",
    "#         x = torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n",
    "#         #x: bs*N x 3 x 128 x 128\n",
    "#         x = self.enc(x)\n",
    "#         #x: bs*N x C x 4 x 4\n",
    "#         shape = x.shape\n",
    "#         #concatenate the output for tiles into a single map\n",
    "#         x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n",
    "#           .view(-1,shape[1],shape[2]*n,shape[3])\n",
    "#         #x: bs x C x N*4 x 4\n",
    "#         x = self.head(x)\n",
    "#         #x: bs x n\n",
    "#         return x\n",
    "    \n",
    "\n",
    "# class CassvaImgClassifier(nn.Module):\n",
    "#     def __init__(self, model_arch, n_class, pretrained=False):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "#         n_features = self.model.classifier.in_features\n",
    "#         self.enc = nn.Sequential(*list(self.model.children())[:-2])\n",
    "# #         self.model.classifier = nn.Linear(n_features, n_class)\n",
    "#         self.head = nn.Sequential(AdaptiveConcatPool2d(),\n",
    "#                                               Flatten(),\n",
    "#                                               nn.Linear(2*n_features,512),\n",
    "#                                               Mish(),\n",
    "#                                               nn.BatchNorm1d(512), \n",
    "#                                               nn.Dropout(0.5),\n",
    "#                                               nn.Linear(512,n_class))\n",
    "            \n",
    "#         '''\n",
    "#         self.model.classifier = nn.Sequential(\n",
    "#             nn.Dropout(0.3),\n",
    "#             #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n",
    "#             nn.Linear(n_features, n_class, bias=True)\n",
    "#         )\n",
    "#         '''\n",
    "#     def forward(self, x):\n",
    "    \n",
    "#         shape = x.shape\n",
    "#         n = 1\n",
    "#         x = x.view(-1,shape[1],shape[2],shape[3])\n",
    "#         #x: bs*N x 3 x 128 x 128\n",
    "#         x = self.enc(x)\n",
    "#         #x: bs*N x C x 4 x 4\n",
    "#         shape = x.shape\n",
    "#         #concatenate the output for tiles into a single map\n",
    "#         x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous().view(-1,shape[1],shape[2]*n,shape[3])\n",
    "#         #x: bs x C x N*4 x 4\n",
    "#         x = self.head(x)\n",
    "#         #x: bs x n\n",
    "#         return x\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "        '''\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n",
    "            nn.Linear(n_features, n_class, bias=True)\n",
    "        )\n",
    "        '''\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x    \n",
    "    \n",
    "class CustomViT(nn.Module):\n",
    "    def __init__(self, model_arch, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        ### vit\n",
    "        num_features = self.model.head.in_features\n",
    "        self.model.head = nn.Linear(num_features, num_classes)\n",
    "        '''\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            #nn.Linear(num_features, hidden_size,bias=True), nn.ELU(),\n",
    "            nn.Linear(num_features, num_classes, bias=True)\n",
    "        )\n",
    "        '''\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "# ====================================================\n",
    "# ResNext Model\n",
    "# ====================================================\n",
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_arch, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        #='resnext50_32x4d',\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CustomViT\n",
    "# CFG = {\n",
    "#     'fold_num': 5,\n",
    "#     'seed': 719,\n",
    "#     'model_arch': 'vit_base_patch16_384',#'tf_efficientnet_b4_ns',\n",
    "#     'img_size': 384,\n",
    "#     'epochs': 10,\n",
    "#     'train_bs': 4,#16,\n",
    "#     'valid_bs': 4,#32,\n",
    "#     'T_0': 10,\n",
    "#     'lr': 1e-4,\n",
    "#     'min_lr': 1e-6,\n",
    "#     'weight_decay':1e-6,\n",
    "#     'num_workers': 0, #4\n",
    "#     'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "#     'verbose_step': 1,\n",
    "#     'device': 'cuda:0',\n",
    "#     'freeze_bn_epochs':5,\n",
    "# }\n",
    "\n",
    "# #CassvaImgClassifier\n",
    "# CFG = {\n",
    "#     'fold_num': 5,\n",
    "#     'seed': 719,\n",
    "#     'model_arch': 'vit_base_patch16_384',#'tf_efficientnet_b4_ns',\n",
    "#     'img_size': 512,\n",
    "#     'epochs': 10,\n",
    "#     'train_bs': 4,#16,\n",
    "#     'valid_bs': 4,#32,\n",
    "#     'T_0': 10,\n",
    "#     'lr': 1e-4,\n",
    "#     'min_lr': 1e-6,\n",
    "#     'weight_decay':1e-6,\n",
    "#     'num_workers': 0, #4\n",
    "#     'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "#     'verbose_step': 1,\n",
    "#     'device': 'cuda:0',\n",
    "#     'freeze_bn_epochs':5,\n",
    "# }\n",
    "\n",
    "# #CustomResNext\n",
    "# CFG = {\n",
    "#     'fold_num': 5,\n",
    "#     'seed': 719,\n",
    "#     'model_arch': 'resnext50_32x4d',#'tf_efficientnet_b4_ns',\n",
    "#     'img_size': 512,\n",
    "#     'epochs': 10,\n",
    "#     'train_bs': 4,#16,\n",
    "#     'valid_bs': 4,#32,\n",
    "#     'T_0': 10,\n",
    "#     'lr': 1e-4,\n",
    "#     'min_lr': 1e-6,\n",
    "#     'weight_decay':1e-6,\n",
    "#     'num_workers': 0, #4\n",
    "#     'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "#     'verbose_step': 1,\n",
    "#     'device': 'cuda:0',\n",
    "#     'freeze_bn_epochs':5,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021054,
     "end_time": "2020-11-23T13:32:51.059722",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.038668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "papermill": {
     "duration": 0.061685,
     "end_time": "2020-11-23T13:32:51.144150",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.082465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root='../input/cassava-leaf-disease-classification/train_images/'):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "        \n",
    "    train_ds = CassavaDataset(train_, data_root, transforms=get_train_transforms(), output_label=True, one_hot_label=False, do_fmix=False, do_cutmix=False)\n",
    "    valid_ds = CassavaDataset(valid_, data_root, transforms=get_valid_transforms(), output_label=True)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        shuffle=True,        \n",
    "        num_workers=CFG['num_workers'],\n",
    "        #sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"downsampling\")\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n",
    "    model.train()\n",
    "\n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "\n",
    "        #print(image_labels.shape, exam_label.shape)\n",
    "        with autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "            #print(image_preds.shape, exam_pred.shape)\n",
    "\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01\n",
    "\n",
    "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n",
    "\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                if scheduler is not None and schd_batch_update:\n",
    "                    scheduler.step()\n",
    "\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                \n",
    "                pbar.set_description(description)\n",
    "                \n",
    "    if scheduler is not None and not schd_batch_update:\n",
    "        scheduler.step()\n",
    "        \n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        #print(image_preds.shape, exam_pred.shape)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]  \n",
    "\n",
    "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
    "            description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "            pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    print('validation multi-class accuracy = {:.4f}'.format((image_preds_all==image_targets_all).mean()))\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        if schd_loss_update:\n",
    "            scheduler.step(loss_sum/sample_num)\n",
    "        else:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "papermill": {
     "duration": 0.034873,
     "end_time": "2020-11-23T13:32:51.200704",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.165831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reference: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/173733\n",
    "class MyCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean'):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"\n",
    "    NLL loss with label smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        \"\"\"\n",
    "        Constructor for the LabelSmoothing module.\n",
    "        :param smoothing: label smoothing factor\n",
    "        \"\"\"\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        assert smoothing < 1.0\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1. - smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = F.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "    \n",
    "    \n",
    "def bi_tempered_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing=0.0,\n",
    "        num_iters=5,\n",
    "        reduction = 'mean'):\n",
    "\n",
    "    \"\"\"Bi-Tempered Logistic Loss.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      labels: A tensor with shape and dtype as activations (onehot), \n",
    "        or a long tensor of one dimension less than activations (pytorch standard)\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing parameter between [0, 1). Default 0.0.\n",
    "      num_iters: Number of iterations to run the method. Default 5.\n",
    "      reduction: ``'none'`` | ``'mean'`` | ``'sum'``. Default ``'mean'``.\n",
    "        ``'none'``: No reduction is applied, return shape is shape of\n",
    "        activations without the last dimension.\n",
    "        ``'mean'``: Loss is averaged over minibatch. Return shape (1,)\n",
    "        ``'sum'``: Loss is summed over minibatch. Return shape (1,)\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(labels.shape)<len(activations.shape): #not one-hot\n",
    "        labels_onehot = torch.zeros_like(activations)\n",
    "        labels_onehot.scatter_(1, labels[..., None], 1)\n",
    "    else:\n",
    "        labels_onehot = labels\n",
    "\n",
    "    if label_smoothing > 0:\n",
    "        num_classes = labels_onehot.shape[-1]\n",
    "        labels_onehot = ( 1 - label_smoothing * num_classes / (num_classes - 1) ) \\\n",
    "                * labels_onehot + \\\n",
    "                label_smoothing / (num_classes - 1)\n",
    "\n",
    "    probabilities = tempered_softmax(activations, t2, num_iters)\n",
    "\n",
    "    loss_values = labels_onehot * log_t(labels_onehot + 1e-10, t1) \\\n",
    "            - labels_onehot * log_t(probabilities, t1) \\\n",
    "            - labels_onehot.pow(2.0 - t1) / (2.0 - t1) \\\n",
    "            + probabilities.pow(2.0 - t1) / (2.0 - t1)\n",
    "    loss_values = loss_values.sum(dim = -1) #sum over classes\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return loss_values\n",
    "    if reduction == 'sum':\n",
    "        return loss_values.sum()\n",
    "    if reduction == 'mean':\n",
    "        return loss_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "papermill": {
     "duration": 0.026635,
     "end_time": "2020-11-23T13:32:49.570638",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.544003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 719,\n",
    "    'model_arch': 'tf_efficientnet_b4_ns',#'tf_efficientnet_b4_ns',\n",
    "    'img_size': 512,\n",
    "    'epochs': 10,\n",
    "    'train_bs': 4,#16,\n",
    "    'valid_bs': 4,#32,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'weight_decay':1e-6,\n",
    "    'num_workers': 0, #4\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'freeze_bn_epochs':5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020806,
     "end_time": "2020-11-23T13:32:51.243006",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.222200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "papermill": {
     "duration": 8602.016415,
     "end_time": "2020-11-23T15:56:13.280909",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.264494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 0 started\n",
      "16261 4066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.6884: 100%|██████████| 4066/4066 [11:52<00:00,  5.71it/s]\n",
      "epoch 0 loss: 0.3718: 100%|██████████| 1017/1017 [01:15<00:00, 13.56it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6499: 100%|██████████| 4066/4066 [11:51<00:00,  5.72it/s]\n",
      "epoch 1 loss: 0.3673: 100%|██████████| 1017/1017 [01:12<00:00, 14.12it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.6567: 100%|██████████| 4066/4066 [11:43<00:00,  5.78it/s]\n",
      "epoch 2 loss: 0.2768: 100%|██████████| 1017/1017 [01:12<00:00, 14.01it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.6666: 100%|██████████| 4066/4066 [11:41<00:00,  5.79it/s]\n",
      "epoch 3 loss: 0.3043: 100%|██████████| 1017/1017 [01:12<00:00, 14.06it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.5576: 100%|██████████| 4066/4066 [11:42<00:00,  5.79it/s]\n",
      "epoch 4 loss: 0.3065: 100%|██████████| 1017/1017 [01:12<00:00, 14.07it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.5690: 100%|██████████| 4066/4066 [11:42<00:00,  5.78it/s]\n",
      "epoch 5 loss: 0.3543: 100%|██████████| 1017/1017 [01:12<00:00, 14.06it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.5462: 100%|██████████| 4066/4066 [11:45<00:00,  5.76it/s]\n",
      "epoch 6 loss: 0.2577: 100%|██████████| 1017/1017 [01:12<00:00, 14.04it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.5296: 100%|██████████| 4066/4066 [11:44<00:00,  5.77it/s]\n",
      "epoch 7 loss: 0.2732: 100%|██████████| 1017/1017 [01:13<00:00, 13.93it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.5067: 100%|██████████| 4066/4066 [11:46<00:00,  5.75it/s]\n",
      "epoch 8 loss: 0.2504: 100%|██████████| 1017/1017 [01:13<00:00, 13.92it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.5171: 100%|██████████| 4066/4066 [11:46<00:00,  5.75it/s]\n",
      "epoch 0 loss: 0.7122: 100%|██████████| 4066/4066 [11:48<00:00,  5.74it/s]\n",
      "epoch 0 loss: 0.3263: 100%|██████████| 1017/1017 [01:12<00:00, 13.99it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6263: 100%|██████████| 4066/4066 [11:52<00:00,  5.71it/s]\n",
      "epoch 1 loss: 0.3169: 100%|██████████| 1017/1017 [01:12<00:00, 13.94it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.5855: 100%|██████████| 4066/4066 [11:50<00:00,  5.72it/s]\n",
      "epoch 2 loss: 0.4226: 100%|██████████| 1017/1017 [01:13<00:00, 13.91it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.5483: 100%|██████████| 4066/4066 [11:50<00:00,  5.72it/s]\n",
      "epoch 3 loss: 0.4731: 100%|██████████| 1017/1017 [01:14<00:00, 13.68it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.5686: 100%|██████████| 4066/4066 [11:52<00:00,  5.71it/s]\n",
      "epoch 4 loss: 0.2946: 100%|██████████| 1017/1017 [01:13<00:00, 13.91it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.5552: 100%|██████████| 4066/4066 [11:53<00:00,  5.70it/s]\n",
      "epoch 5 loss: 0.3553: 100%|██████████| 1017/1017 [01:14<00:00, 13.74it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.5426: 100%|██████████| 4066/4066 [11:53<00:00,  5.70it/s]\n",
      "epoch 6 loss: 0.2924: 100%|██████████| 1017/1017 [01:13<00:00, 13.83it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.5474: 100%|██████████| 4066/4066 [11:53<00:00,  5.70it/s]\n",
      "epoch 7 loss: 0.2659: 100%|██████████| 1017/1017 [01:14<00:00, 13.74it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.5512: 100%|██████████| 4066/4066 [11:53<00:00,  5.70it/s]\n",
      "epoch 8 loss: 0.2576: 100%|██████████| 1017/1017 [01:14<00:00, 13.72it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.5287: 100%|██████████| 4066/4066 [11:53<00:00,  5.70it/s]\n",
      "epoch 9 loss: 0.2622: 100%|██████████| 1017/1017 [01:13<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9407\n",
      "Training with 2 started\n",
      "16262 4065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.6665: 100%|██████████| 4066/4066 [11:58<00:00,  5.66it/s]\n",
      "epoch 0 loss: 0.3472: 100%|██████████| 1017/1017 [01:14<00:00, 13.70it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6148: 100%|██████████| 4066/4066 [11:55<00:00,  5.68it/s]\n",
      "epoch 1 loss: 0.3111: 100%|██████████| 1017/1017 [01:13<00:00, 13.89it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.6257: 100%|██████████| 4066/4066 [11:57<00:00,  5.67it/s]\n",
      "epoch 2 loss: 0.2830: 100%|██████████| 1017/1017 [01:13<00:00, 13.92it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.6356: 100%|██████████| 4066/4066 [11:57<00:00,  5.66it/s]\n",
      "epoch 3 loss: 0.2936: 100%|██████████| 1017/1017 [01:13<00:00, 13.87it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 loss: 0.5770: 100%|██████████| 4066/4066 [11:57<00:00,  5.67it/s]\n",
      "epoch 4 loss: 0.3623: 100%|██████████| 1017/1017 [01:13<00:00, 13.88it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.8937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.5577: 100%|██████████| 4066/4066 [12:01<00:00,  5.64it/s]\n",
      "epoch 5 loss: 0.2836: 100%|██████████| 1017/1017 [01:13<00:00, 13.82it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.5475: 100%|██████████| 4066/4066 [11:59<00:00,  5.65it/s]\n",
      "epoch 6 loss: 0.2696: 100%|██████████| 1017/1017 [01:13<00:00, 13.88it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 loss: 0.5312: 100%|██████████| 4066/4066 [11:59<00:00,  5.65it/s]\n",
      "epoch 7 loss: 0.2485: 100%|██████████| 1017/1017 [01:13<00:00, 13.88it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.5147: 100%|██████████| 4066/4066 [12:01<00:00,  5.64it/s]\n",
      "epoch 8 loss: 0.2765: 100%|██████████| 1017/1017 [01:13<00:00, 13.84it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.5371: 100%|██████████| 4066/4066 [12:01<00:00,  5.64it/s]\n",
      "epoch 9 loss: 0.2501: 100%|██████████| 1017/1017 [01:13<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9348\n",
      "Training with 3 started\n",
      "16262 4065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.2816: 100%|██████████| 1017/1017 [01:13<00:00, 13.82it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6057: 100%|██████████| 4066/4066 [11:57<00:00,  5.66it/s]\n",
      "epoch 1 loss: 0.2977: 100%|██████████| 1017/1017 [01:13<00:00, 13.83it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.6261: 100%|██████████| 4066/4066 [12:01<00:00,  5.63it/s]\n",
      "epoch 2 loss: 0.2581: 100%|██████████| 1017/1017 [01:13<00:00, 13.87it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.5868: 100%|██████████| 4066/4066 [12:00<00:00,  5.64it/s]\n",
      "epoch 4 loss: 0.5644: 100%|██████████| 4066/4066 [12:03<00:00,  5.62it/s]\n",
      "epoch 4 loss: 0.2782: 100%|██████████| 1017/1017 [01:14<00:00, 13.73it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.5313: 100%|██████████| 4066/4066 [12:05<00:00,  5.61it/s]\n",
      "epoch 5 loss: 0.2680: 100%|██████████| 1017/1017 [01:13<00:00, 13.89it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 loss: 0.5482: 100%|██████████| 4066/4066 [12:03<00:00,  5.62it/s]\n",
      "epoch 7 loss: 0.5147: 100%|██████████| 4066/4066 [12:03<00:00,  5.62it/s]\n",
      "epoch 7 loss: 0.2685: 100%|██████████| 1017/1017 [01:13<00:00, 13.75it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.5169: 100%|██████████| 4066/4066 [12:04<00:00,  5.62it/s]\n",
      "epoch 8 loss: 0.2604: 100%|██████████| 1017/1017 [01:13<00:00, 13.75it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.5246: 100%|██████████| 4066/4066 [12:03<00:00,  5.62it/s]\n",
      "epoch 9 loss: 0.2561: 100%|██████████| 1017/1017 [01:12<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9383\n",
      "Training with 4 started\n",
      "16262 4065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 0.6738: 100%|██████████| 4066/4066 [12:05<00:00,  5.60it/s]\n",
      "epoch 0 loss: 0.3174: 100%|██████████| 1017/1017 [01:13<00:00, 13.75it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6275: 100%|██████████| 4066/4066 [11:59<00:00,  5.65it/s]\n",
      "epoch 1 loss: 0.2993: 100%|██████████| 1017/1017 [01:13<00:00, 13.79it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 loss: 0.6080: 100%|██████████| 4066/4066 [11:56<00:00,  5.67it/s]\n",
      "epoch 2 loss: 0.3250: 100%|██████████| 1017/1017 [01:13<00:00, 13.78it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 loss: 0.5898: 100%|██████████| 4066/4066 [11:57<00:00,  5.67it/s]\n",
      "epoch 4 loss: 0.5540: 100%|██████████| 4066/4066 [11:59<00:00,  5.65it/s]\n",
      "epoch 4 loss: 0.2881: 100%|██████████| 1017/1017 [01:13<00:00, 13.92it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 loss: 0.5512: 100%|██████████| 4066/4066 [11:54<00:00,  5.69it/s]\n",
      "epoch 6 loss: 0.5230: 100%|██████████| 4066/4066 [11:57<00:00,  5.67it/s]\n",
      "epoch 7 loss: 0.5122: 100%|██████████| 4066/4066 [12:08<00:00,  5.58it/s]\n",
      "epoch 7 loss: 0.2797: 100%|██████████| 1017/1017 [01:13<00:00, 13.86it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 loss: 0.5106: 100%|██████████| 4066/4066 [12:03<00:00,  5.62it/s]\n",
      "epoch 8 loss: 0.2764: 100%|██████████| 1017/1017 [01:12<00:00, 14.11it/s]\n",
      "  0%|          | 0/4066 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 loss: 0.2875: 100%|██████████| 1017/1017 [01:12<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation multi-class accuracy = 0.9250\n"
     ]
    }
   ],
   "source": [
    "################ freeze bn \n",
    "def freeze_batchnorm_stats(net):\n",
    "    try:\n",
    "        for m in net.modules():\n",
    "            if isinstance(m,nn.BatchNorm2d) or isinstance(m,nn.LayerNorm):\n",
    "                m.eval()\n",
    "    except ValuError:\n",
    "        print('error with batchnorm2d or layernorm')\n",
    "        return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     # for training only, need nightly build pytorch\n",
    "\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        # we'll train fold 0 first\n",
    "\n",
    "        print('Training with {} started'.format(fold))\n",
    "\n",
    "        print(len(trn_idx), len(val_idx))\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root='../input/cassava-leaf-disease-classification/train_images/')\n",
    "\n",
    "        device = torch.device(CFG['device'])\n",
    "        \n",
    "        model = CassvaImgClassifier(CFG['model_arch'], train.label.nunique(), pretrained=True).to(device)\n",
    "        scaler = GradScaler()   \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "        #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.1, step_size=CFG['epochs']-1)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n",
    "        #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=25, \n",
    "        #                                                max_lr=CFG['lr'], epochs=CFG['epochs'], steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        loss_tr = LabelSmoothingCrossEntropy().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "        \n",
    "        for epoch in range(CFG['epochs']):\n",
    "#             if epoch < CFG['freeze_bn_epochs']:\n",
    "#                 freeze_batchnorm_stats(model)  \n",
    "            \n",
    "            train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "\n",
    "            torch.save(model.state_dict(),'{}_fold_{}'.format(CFG['model_arch'], fold))\n",
    "            \n",
    "#         torch.save(model.cnn_model.state_dict(),'{}/cnn_model_fold_{}_{}'.format(CFG['model_path'], fold, CFG['tag']))\n",
    "        del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference fold 0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:18<00:00,  1.72it/s]\n",
      "100%|██████████| 134/134 [01:15<00:00,  1.78it/s]\n",
      "100%|██████████| 134/134 [01:14<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 validation loss = 0.35060\n",
      "fold 0 validation accuracy = 0.91565\n",
      "Inference fold 1 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:15<00:00,  1.78it/s]\n",
      "100%|██████████| 134/134 [01:16<00:00,  1.75it/s]\n",
      "100%|██████████| 134/134 [01:15<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 validation loss = 0.35959\n",
      "fold 1 validation accuracy = 0.90958\n",
      "Inference fold 2 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:19<00:00,  1.68it/s]\n",
      "100%|██████████| 134/134 [01:16<00:00,  1.75it/s]\n",
      "100%|██████████| 134/134 [01:15<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 validation loss = 0.31200\n",
      "fold 2 validation accuracy = 0.92218\n",
      "Inference fold 3 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:15<00:00,  1.77it/s]\n",
      "100%|██████████| 134/134 [01:16<00:00,  1.75it/s]\n",
      "100%|██████████| 134/134 [01:18<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 validation loss = 0.35316\n",
      "fold 3 validation accuracy = 0.91447\n",
      "Inference fold 4 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:18<00:00,  1.71it/s]\n",
      "100%|██████████| 134/134 [01:15<00:00,  1.77it/s]\n",
      "100%|██████████| 134/134 [01:17<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 validation loss = 0.36121\n",
      "fold 4 validation accuracy = 0.90816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n",
    "\n",
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 719,\n",
    "    'model_arch': 'tf_efficientnet_b4_ns',\n",
    "    'img_size': 512,\n",
    "    'epochs': 10,\n",
    "    'train_bs': 32,\n",
    "    'valid_bs': 32,\n",
    "    'lr': 1e-4,\n",
    "    'num_workers': 0,\n",
    "    'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'tta': 3,\n",
    "    'weights': [1,1,1,1,1]\n",
    "}\n",
    "\n",
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        \n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all\n",
    "\n",
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     # for training only, need nightly build pytorch\n",
    "\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        # we'll train fold 0 first\n",
    "\n",
    "        print('Inference fold {} started'.format(fold))\n",
    "\n",
    "        valid_ = train.loc[val_idx,:].reset_index(drop=True)\n",
    "        valid_ds = CassavaDataset(valid_, '../input/cassava-leaf-disease-classification/train_images/', transforms=get_inference_transforms(), output_label=False)\n",
    "        \n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            valid_ds, \n",
    "            batch_size=CFG['valid_bs'],\n",
    "            num_workers=CFG['num_workers'],\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "        )\n",
    "\n",
    "        device = torch.device(CFG['device'])\n",
    "        model = CassvaImgClassifier(CFG['model_arch'], train.label.nunique()).to(device)\n",
    "        \n",
    "        val_preds = []\n",
    "        \n",
    "        #for epoch in range(CFG['epochs']-3):    \n",
    "        model.load_state_dict(torch.load('{}_fold_{}'.format(CFG['model_arch'], fold)))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(CFG['tta']):\n",
    "                val_preds += [1/CFG['tta']*inference_one_epoch(model, val_loader, device)]\n",
    "                \n",
    "        val_preds = np.mean(val_preds, axis=0) \n",
    "        \n",
    "        \n",
    "        print('fold {} validation loss = {:.5f}'.format(fold, log_loss(valid_.label.values, val_preds)))\n",
    "        print('fold {} validation accuracy = {:.5f}'.format(fold, (valid_.label.values==np.argmax(val_preds, axis=1)).mean()))\n",
    "        \n",
    "        oof_ = pd.concat([valid_, pd.DataFrame(val_preds, columns=[f'soft_label_{i}' for i in range(1,6)])], axis=1)\n",
    "        oof_.to_pickle(f\"{CFG['model_arch']}_oof{fold}.pkl\")\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-64-53e7ad4baecf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-64-53e7ad4baecf>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    v1 baseline accuracy = 0.8857\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "v1 baseline accuracy = 0.8857\n",
    "v2 v1=> change LabelSmoothingCrossEntropy accuracy = 0.8874\n",
    "v3 v2=> add freeze_batchnorm_stats accuracy = 0.8874 no change\n",
    "v4 v2=> remove some aug accuracy = 0.8937\n",
    "v5 v4=> use ViT accuracy = 0.8837\n",
    "v6 v4=> use resnext accuracy = 0.8734\n",
    "v7 v4=> only classify 0,1,2,4 cause 3 is too much accuracy = 0.85\n",
    "v8 v4=> remove noisy image by oof accuracy = 0.93\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 8.681322,
     "end_time": "2020-11-23T15:56:30.750663",
     "exception": false,
     "start_time": "2020-11-23T15:56:22.069341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inferece part is here: https://www.kaggle.com/khyeh0719/pytorch-efficientnet-baseline-inference-tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "duration": 8637.721674,
   "end_time": "2020-11-23T15:56:40.428882",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-23T13:32:42.707208",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
