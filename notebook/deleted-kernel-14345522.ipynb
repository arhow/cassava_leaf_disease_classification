{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\anaconda3\\envs\\tf_gpu23-2\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import albumentations\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "import scipy as sp\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# PATH\n",
    "# ====================================================\n",
    "TRAIN_PATH = '../input/cassava-leaf-disease-classification/train_images'\n",
    "TEST_PATH = '../input/cassava-leaf-disease-classification/test_images'\n",
    "# ====================================================\n",
    "# test data\n",
    "# ====================================================\n",
    "test = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\n",
    "test['filepath'] = test.image_id.apply(lambda x: os.path.join('../input/cassava-leaf-disease-classification/test_images', f'{x}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Using Seed :  1992  ]\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CFG for Resnext\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug=False\n",
    "    image_size = 512\n",
    "    num_workers=0 # 4\n",
    "    model_name='resnext50_32x4d'\n",
    "    size=512\n",
    "    batch_size=32\n",
    "    seed=1992\n",
    "    num_classes=5\n",
    "    target_col='label'\n",
    "    resnext = 'resnext50_32x4d'\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    inference=True\n",
    "\n",
    "# ====================================================\n",
    "# RANDOM SEED\n",
    "# ====================================================\n",
    "def seed_all(seed: int):\n",
    "    if not seed:\n",
    "        seed = 10\n",
    "\n",
    "    print(\"[ Using Seed : \", seed, \" ]\")\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # set PYTHONHASHSEED env var at fixed value\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed) # pytorch (both CPU and CUDA)\n",
    "    np.random.seed(seed) # for numpy pseudo-random generator\n",
    "    random.seed(seed) # set fixed value for python built-in pseudo-random generator\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    \n",
    "seed_all(seed=CFG.seed)\n",
    "\n",
    "# ====================================================\n",
    "# Dataset for Resnext\n",
    "# ====================================================\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{TEST_PATH}/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image\n",
    "    \n",
    "# ====================================================\n",
    "# Transforms for Resnext\n",
    "# ====================================================\n",
    "import albumentations as A\n",
    "def get_transforms(*, data):\n",
    "    if data == 'valid':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.size, CFG.size),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "# ====================================================\n",
    "# ResNext Model\n",
    "# ====================================================\n",
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_arc, num_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name=model_arc, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, num_classes)\n",
    "        \n",
    "    def forward(self, input_neurons):\n",
    "        # TODO: add dropout layers, or the likes.\n",
    "        output_predictions = self.model(input_neurons)\n",
    "        return output_predictions\n",
    "    \n",
    "# ====================================================\n",
    "# inference\n",
    "# ====================================================\n",
    "def load_state(model_path):\n",
    "    model = CustomResNext(CFG.model_name, CFG.num_classes, pretrained=False)\n",
    "    try:  # single GPU model_file\n",
    "        model.load_state_dict(torch.load(model_path)['model'], strict=True)\n",
    "        state_dict = torch.load(model_path)['model']\n",
    "    except:  # multi GPU model_file\n",
    "        state_dict = torch.load(model_path)['model']\n",
    "        state_dict = {k[7:] if k.startswith('module.') else k: state_dict[k] for k in state_dict.keys()}\n",
    "\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "def inference(model, states, test_loader, device):\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "        \n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06168885, 0.15705398, 0.32266027, 0.07326578, 0.38533115]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for Resnext\n",
    "MODEL_DIR = '../input/cassavaroots/'\n",
    "model = CustomResNext(CFG.model_name, CFG.num_classes, pretrained=False)\n",
    "states = [load_state(f'{MODEL_DIR}{CFG.model_name}_fold{fold}.pth') for fold in CFG.trn_fold]\n",
    "test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False,  num_workers=CFG.num_workers, pin_memory=True)\n",
    "resnext_predictions = inference(model, states, test_loader, device)\n",
    "resnext_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[0.04188796, 0.04432843, 0.24820718, 0.03057373, 0.63500273]],\n",
    "#       dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Using Seed :  1992  ]\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# CFG for Resnext\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug=False\n",
    "    num_workers=0#4\n",
    "    model_name='resnext50_32x4d'\n",
    "    image_size=512\n",
    "    batch_size=1\n",
    "    seed=1992\n",
    "    num_classes=5\n",
    "    target_col='label'\n",
    "    resnext = 'resnext50_32x4d'\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    inference=True\n",
    "    \n",
    "# ====================================================\n",
    "# seed\n",
    "# ====================================================\n",
    "\n",
    "def seed_all(seed: int):\n",
    "    if not seed:\n",
    "        seed = 10\n",
    "\n",
    "    print(\"[ Using Seed : \", seed, \" ]\")\n",
    "    \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # set PYTHONHASHSEED env var at fixed value\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed) # pytorch (both CPU and CUDA)\n",
    "    np.random.seed(seed) # for numpy pseudo-random generator\n",
    "    random.seed(seed) # set fixed value for python built-in pseudo-random generator\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    \n",
    "seed_all(seed=CFG.seed)\n",
    "    \n",
    "# ====================================================\n",
    "# Dataset for efficientnet\n",
    "# ====================================================\n",
    "class CLDDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.loc[index]\n",
    "        image = cv2.imread(row.filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            res = self.transform(image=image)\n",
    "            image = res['image']\n",
    "        \n",
    "        image = image.astype(np.float32)\n",
    "        image = image.transpose(2,0,1)\n",
    "        if self.mode == 'test':\n",
    "            return torch.tensor(image).float()\n",
    "        else:\n",
    "            return torch.tensor(image).float(), torch.tensor(row.label).float()    \n",
    "        \n",
    "    \n",
    "# ====================================================\n",
    "# EfficientNet Model\n",
    "# ====================================================\n",
    "class enet_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, backbone, out_dim, pretrained=False):\n",
    "        super(enet_v2, self).__init__()\n",
    "        self.enet = timm.create_model(backbone, pretrained=pretrained)\n",
    "        in_ch = self.enet.classifier.in_features\n",
    "        self.myfc = nn.Linear(in_ch, out_dim)\n",
    "        self.enet.classifier = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enet(x)\n",
    "        x = self.myfc(x)\n",
    "        return x    \n",
    "    \n",
    "    \n",
    "class CustomEfficientNet(nn.Module):\n",
    "    def __init__(self, config: type, pretrained: bool=True):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = geffnet.create_model(\n",
    "#             model_weight_path_folder=config.paths['model_weight_path_folder'],\n",
    "            model_name=config.effnet,\n",
    "            pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, config.num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, input_neurons):\n",
    "        # TODO: add dropout layers, or the likes.\n",
    "        output_predictions = self.model(input_neurons)\n",
    "        return output_predictions\n",
    "    \n",
    "# ====================================================\n",
    "# Helper functions for efficientnet\n",
    "# ====================================================\n",
    "def inference_func(test_loader):\n",
    "    model.eval()\n",
    "    bar = tqdm(test_loader)\n",
    "\n",
    "    LOGITS = []\n",
    "    PREDS = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, images in enumerate(bar):\n",
    "            x = images.to(device)\n",
    "            logits = model(x)\n",
    "            LOGITS.append(logits.cpu())\n",
    "            PREDS += [torch.softmax(logits, 1).detach().cpu()]\n",
    "        PREDS = torch.cat(PREDS).cpu().numpy()\n",
    "        LOGITS = torch.cat(LOGITS).cpu().numpy()\n",
    "    return PREDS\n",
    "\n",
    "def tta_inference_func(test_loader):\n",
    "    model.eval()\n",
    "    bar = tqdm(test_loader)\n",
    "    PREDS = []\n",
    "    LOGITS = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, images in enumerate(bar):\n",
    "            x = images.to(device)\n",
    "            x = torch.stack([x,x.flip(-1),x.flip(-2),x.flip(-1,-2),\n",
    "            x.transpose(-1,-2),x.transpose(-1,-2).flip(-1),\n",
    "            x.transpose(-1,-2).flip(-2),x.transpose(-1,-2).flip(-1,-2)],0)\n",
    "            x = x.view(-1, 3, CFG.image_size, CFG.image_size)\n",
    "            logits = model(x)\n",
    "            logits = logits.view(CFG.batch_size, 8, -1).mean(1)\n",
    "            PREDS += [torch.softmax(logits, 1).detach().cpu()]\n",
    "            LOGITS.append(logits.cpu())\n",
    "\n",
    "        PREDS = torch.cat(PREDS).cpu().numpy()\n",
    "        \n",
    "    return PREDS\n",
    "\n",
    "#Transform for efficientnet\n",
    "transforms_valid = albumentations.Compose([\n",
    "    albumentations.CenterCrop(CFG.image_size, CFG.image_size, p=1),\n",
    "    albumentations.Resize(CFG.image_size, CFG.image_size),\n",
    "    albumentations.Normalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03165457, 0.02644922, 0.15103984, 0.00727853, 0.7835778 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for Efficientnet\n",
    "enet_type = ['tf_efficientnet_b4_ns'] * 5\n",
    "model_path = ['../input/cassavaroots/baseline_cld_fold0_epoch8_tf_efficientnet_b4_ns_512.pth', \n",
    "              '../input/cassavaroots/baseline_cld_fold1_epoch9_tf_efficientnet_b4_ns_512.pth', \n",
    "              '../input/cassavaroots/baseline_cld_fold2_epoch9_tf_efficientnet_b4_ns_512.pth',\n",
    "              '../input/cassavaroots/baseline_cld_fold3_epoch5_tf_efficientnet_b4_ns_512.pth',\n",
    "              '../input/cassavaroots/baseline_cld_fold4_epoch11_tf_efficientnet_b4_ns_512.pth']\n",
    "\n",
    "\n",
    "#for efficientnet\n",
    "test_dataset_efficient = CLDDataset(test, 'test', transform=transforms_valid)\n",
    "test_loader_efficient = torch.utils.data.DataLoader(test_dataset_efficient, batch_size=CFG.batch_size, shuffle=False,  num_workers=CFG.num_workers)\n",
    "\n",
    "efb4_predictions = []\n",
    "for i in range(len(enet_type)):\n",
    "    model = enet_v2(enet_type[i], out_dim=5)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path[i]))\n",
    "    efb4_predictions += [tta_inference_func(test_loader_efficient)]\n",
    "efb4_predictions = np.mean(efb4_predictions, axis=0)\n",
    "efb4_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import random\n",
    "import cv2\n",
    "from imgaug import augmenters as iaa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.experimental import CosineDecay\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomCrop,CenterCrop, RandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG for keras ef b3\n",
    "# ====================================================\n",
    "# batch_size = 4\n",
    "image_size = 512\n",
    "input_shape = (image_size, image_size, 3)\n",
    "dropout_rate = 0.4\n",
    "# classes_to_predict = sorted(training_df.label.unique())\n",
    "n_ouput = 5\n",
    "\n",
    "# ====================================================\n",
    "# build the ef graph\n",
    "# ====================================================\n",
    "def build_graph(weights=None):\n",
    "    data_augmentation_layers = tf.keras.Sequential(\n",
    "        [\n",
    "            layers.experimental.preprocessing.RandomCrop(height=image_size, width=image_size),\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(0.25),\n",
    "            layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n",
    "            layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    efficientnet = EfficientNetB3(#weights='../model/efficientnet-b3_noisy-student.h5', \n",
    "                                  include_top=False, \n",
    "                                  input_shape=input_shape, \n",
    "                                  drop_connect_rate=dropout_rate)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    augmented = data_augmentation_layers(inputs)\n",
    "    efficientnet = efficientnet(augmented)\n",
    "    pooling = layers.GlobalAveragePooling2D()(efficientnet)\n",
    "    dropout = layers.Dropout(dropout_rate)(pooling)\n",
    "    outputs = Dense(n_ouput, activation=\"softmax\")(dropout)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    if weights!=None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "test_time_augmentation_layers = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n",
    "        layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n",
    "    ]\n",
    ")\n",
    "\n",
    "def scan_over_image(img_path, crop_size=512):\n",
    "    '''\n",
    "    Will extract 512x512 images covering the whole original image\n",
    "    with some overlap between images\n",
    "    '''\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    img_height, img_width = img.size\n",
    "    img = np.array(img)\n",
    "    \n",
    "    y = random.randint(0,img_height-crop_size)\n",
    "    x = random.randint(0,img_width-crop_size)\n",
    "\n",
    "    x_img_origins = [0,img_width-crop_size]\n",
    "    y_img_origins = [0,img_height-crop_size]\n",
    "    img_list = []\n",
    "    for x in x_img_origins:\n",
    "        for y in y_img_origins:\n",
    "            img_list.append(img[x:x+crop_size , y:y+crop_size,:])\n",
    "  \n",
    "    return np.array(img_list)\n",
    "\n",
    "def predict_and_vote(models, image_filename, folder, TTA_runs=4):\n",
    "    '''\n",
    "    Run the model over 4 local areas of the given image,\n",
    "    before making a decision depending on the most predicted\n",
    "    disease.\n",
    "    '''\n",
    "    \n",
    "    #apply TTA to each of the 4 images and sum all predictions for each local image\n",
    "    localised_predictions = []\n",
    "    local_image_list = scan_over_image(folder+image_filename)\n",
    "    for local_image in local_image_list:\n",
    "        duplicated_local_image = tf.convert_to_tensor(np.array([local_image for i in range(TTA_runs)]))\n",
    "        augmented_images = test_time_augmentation_layers(duplicated_local_image)\n",
    "        predictions = models[0].predict(augmented_images)\n",
    "        for m in models[1:]:\n",
    "            predictions += m.predict(augmented_images)\n",
    "        predictions /= len(models)\n",
    "        localised_predictions.append(np.mean(predictions, axis=0))\n",
    "    \n",
    "    #sum all predictions from all 4 images and retrieve the index of the highest value\n",
    "    global_predictions = np.mean(np.array(localised_predictions),axis=0)\n",
    "#     final_prediction = np.argmax(global_predictions)\n",
    "    \n",
    "    return global_predictions\n",
    "\n",
    "def run_predictions_over_image_list(models, image_list, folder):\n",
    "    predictions = []\n",
    "    with tqdm(total=len(image_list)) as pbar:\n",
    "        for image_filename in image_list:\n",
    "            pbar.update(1)\n",
    "            predictions.append(predict_and_vote(models, image_filename, folder))\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C2C3981E58> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 21 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C2CAD62828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.24s/it]\n"
     ]
    }
   ],
   "source": [
    "test_folder = '../input/cassava-leaf-disease-classification/test_images/'\n",
    "model_folder = '../input/keras-efficientnet/'\n",
    "model_paths = [f'{model_folder}{f}' for f in os.listdir(model_folder) if 'fold' in f]\n",
    "models =  []\n",
    "for m_p in model_paths:\n",
    "    models.append(build_graph(m_p))\n",
    "kefb3_predictions = run_predictions_over_image_list(models, test.image_id, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './'\n",
    "pred = (resnext_predictions + efb4_predictions + kefb3_predictions)/3\n",
    "test['label'] = softmax(pred).argmax(1)\n",
    "test[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
